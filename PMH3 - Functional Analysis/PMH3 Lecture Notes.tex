% Created by Andrew Tulloch

%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode


\documentclass[10pt, oneside, reqno]{amsart}
\usepackage{geometry, setspace, graphicx, enumerate, amssymb}
\onehalfspacing                 
\usepackage{fontspec,xltxtra,xunicode}
\defaultfontfeatures{Mapping=tex-text}
            

% AMS Theorems
\theoremstyle{plain}% default 
\newtheorem{thm}{Theorem}[section] 
\newtheorem{lem}[thm]{Lemma} 
\newtheorem{prop}[thm]{Proposition} 
\newtheorem*{cor}{Corollary} 

\theoremstyle{definition} 
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark} 
\newtheorem*{rem}{Remark} 
\newtheorem*{note}{Note} 
\newtheorem{case}{Case} 

\newcommand{\expc}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\cov}[1]{\text{Cov}\left(#1\right)}
\newcommand{\prob}[1]{\mathbb{P}(#1)}
\newcommand{\given}{ \, | \,}
\newcommand{\us}{0 \leq u \leq s}
\newcommand{\ts}[1]{\{ #1 \}}

\newcommand{\dzz}{\, dz}
\newcommand{\bigo}[1]{\mathcal{O}(#1)}

% Maths Field Symbols
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Hil}{\mathcal{H}}

\newcommand{\Com}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Ga}{\mathbb{G}}

\newcommand{\aut}[1]{\text{Aut}{(#1)}}

\newcommand{\gener}[1]{\langle #1 \rangle}
\newcommand{\charr}[1]{\text{char}(#1)}
\newcommand{\nth}{n\textsuperscript{th}}

\newcommand{\tworow}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}
\newcommand{\xdeg}[2]{[#1 : #2]}
\newcommand{\gal}[2]{\text{Gal}(#1/#2)}
\newcommand{\minpoly}[2]{m_{#1, #2}(x)}
\renewcommand{\Re}{\text{Re}}

\newcommand{\mapping}[5]{\begin{align*}
    #1 : \,     #2 &\rightarrow #3 \\
            #4  &\mapsto #5
\end{align*}    
}

\newcommand{\hilb}{(\Hil, \langle \cdot, \cdot, \rangle )}
\renewcommand{\phi}{\varphi}
        
        
\newcommand{\iprod}[1]{\left\langle #1 \right\rangle}
\newcommand{\sumkn}{\sum_{k=1}^n}
\newcommand{\sumin}{\sum_{i=1}^n}
\newcommand{\sumkinf}{\sum_{k=1}^\infty}
\newcommand{\sumiinf}{\sum_{i=1}^\infty}
\newcommand{\spans}{\text{span}\ }
\newcommand{\im}{\textsc{Im\ }}
\renewcommand{\ker}{\textsc{Ker\ }}

\usepackage{hyperref}

\title{PMH3 - Functional Analysis}                              % Document Title
\author{Andrew Tulloch}
%\date{}                                           % Activate to display a given date or no date


\begin{document}
\maketitle \tableofcontents \clearpage

\section{Lecture 1 - Monday 28 February} % (fold)
\label{sec:lecture_1_28_february}

% Norms, metrics, Lp spaces, Banach Space, Inner Product Space, Normed Space, etc.  
\begin{defn}[Norm]
    Let $X$ be a vector space.  A norm on $X$ is a function $\| \cdot \| : X \mapsto \R$ satisfying 
    \begin{itemize}
        \item $\| x \| \geq 0$ with equality if and only if $x = 0$.  
        \item $\| \alpha x \| = | \alpha | \| x \|$.
        \item $\| x + y \| \leq \| x \| + \| y \|$ for all $x, y \in X$.  
    \end{itemize}
    
    We call the pair $(X, \| \cdot \|)$ a \textbf{normed vector space.}
\end{defn}

\begin{thm}[Reverse triangle inequality]
    Let $X$ be a normed vector space.  For any $x, y \in X$, we have \[
        \left| \|x \| - \| y \| \right| \leq \| x - y \|  
    \]
\end{thm}

\begin{defn}[Complete space]
    Let $X$ be a normed vector space.  Then $X$ is \textbf{complete} if every Cauchy sequence in $X$ converges to some $x \in X$.  
\end{defn}

\begin{defn}[Banach space]
    A \textbf{Banach space} is a complete normed vector space.
\end{defn}


% section lecture_1_28_february (end)

\section{Lecture 2 - Wednesday 2 March} % (fold)
\label{sec:lecture_2_2_march}

\begin{prop}[Convergence] Let $(V, \| \cdot \| )$ be a normed vector space.  A sequence $(x_n)$ in $V$ converges to $x \in V$ if given $\epsilon > 0$, there exists $N$ such that $\| x - x_n \| < \epsilon$ whenever $n < N$. 
\end{prop}

\begin{lem}
    If $x_n \rightarrow x$, then $\| x_n \| \rightarrow \| x \| \in \R$.
    \begin{proof}
        $\left| \| x_n \| - \| x \| \right| \leq \| x - x_n \| \rightarrow 0$.
    \end{proof}
\end{lem}

\begin{prop}
    Every convergent sequence is Cauchy.
\end{prop}

\begin{defn}[Banach space]
A complete, normed, vector space is called a \textbf{Banach space}
\end{defn}

\begin{prop}
    $( \K, |\cdot |)$ is complete.
\end{prop}

\begin{prop}
    $(\ell^p, \| \cdot \|_p)$ is a Banach space for all $1 \leq p \leq \infty$
\end{prop}

\begin{proof}
    A general proof outline follows.
    \begin{itemize}
        \item Use completeness of $\R$ to find a candidate for the limit.
        \item Show this limit function is in $V$.
        \item Show that $x_n \rightarrow x$ in $V$.
    \end{itemize}
    Let $x^{(n)}$ be a Cauchy sequence in $\ell^p$.  Since $|x_j^{(n)} - x_{j}^{(n)}| \leq \|x^{(n)} - x^{(m)}\|$, we know that $x^{(n)}_j$ is a Cauchy sequence in $\K$.  Hence, $\lim_{n \rightarrow \infty} x^{(n)}_j := x_j$ exists, and is our limit candidate.
    
    We now show that $\sum_{j =1}^\infty |x_j|^p < \infty$.  We have 
\end{proof}

\begin{prop}
    ($\ell([a,b]), \|\cdot \|_\infty$) is a Banach space
\end{prop}

\begin{prop}
    If $1 \leq p < \infty$, then $(\ell([a,b]), \| \cdot \|_p)$ is \textbf{not} a Banach space.
\end{prop}
\begin{proof}
    Consider a sequence of functions that is equal to one on $[0, \frac{1}{2}]$, zero on $[\frac{1}{2}+ \frac{1}{n}, 1]$, and linear between.  This is a Cauchy sequence that does not converge to a continuous function. 
\end{proof}
% section lecture_2_2_march (end)

\section{Lecture 3 - Monday 7 March} % (fold)
\label{sec:lecture_3_monday_7_march}
We've seen that $(\ell([a,b]), \| \cdot \|_p)$ is not complete for $1 \leq p < \infty$.  

\begin{thm}[Completion] Let $(V, \| \cdot \| )$ be a normed vector space over $\K$.  There exists a Banach space ($V_1, \| \cdot \|_1$) such that $( V, \| \cdot \|)$ is isometrically isomorphic to a dense subspace of $(V_1, \| \cdot \|_1)$.  
    
    Furthermore, the space $( V_1, \| \cdot \|_1)$ is unique up to isometric isomorphisms.  
\end{thm}

\begin{proof}
    Rather straightforward - construct Cauchy sequences, append limits, quotient out (as different sequences may converge to the same limit).
\end{proof}

\begin{defn}[] $(V_1, \| \cdot \|_1)$ is called \textbf{the completion} of $(V, \| \cdot \|)$. 
\end{defn}

\begin{defn}[Dense]
    If $X$ is a topological space and $Y \subseteq X$, then $Y$ is \textbf{dense} in $X$ if the closure of $Y$ in $X$ equals $X$, that is, $\overline{Y} = X$.

Alternatively, for each $x \in X$, there exists $(y_n)$ in $Y$ such that $y_n \rightarrow x$.
\end{defn}

\begin{defn}[Isomorphism of vector spaces]
    Two normed vector spaces $(X, \| \cdot \|X)$ and $(Y, \| \cdot \|Y)$ are \textbf{isometrically isomorphic} if there is a vector space isomorphism $\Psi: X \rightarrow Y$ such that \[
        \| \Psi(x) \|_Y = \| x \|_X \quad \forall x \in X
    \]
\end{defn}

\begin{exmp}
    Let $\ell_0 = \{ (x_i) \, | \, \# \{ i, x_i \neq 0 \} < \infty \}$.  The completion of $\ell_0, \| \cdot \|_p$ is $(\ell^p, \| \cdot \|_p )$, because,
    \begin{itemize}
        \item $\ell_0$ is a subspace of $\ell^p$,
        \item It is dense, since we can easily construct a sequence in $\ell_0$ converging to arbitrary $x \in \ell^p$.
    \end{itemize}
\end{exmp}
% % 
\begin{exmp}[ $L^p$ spaces]
    Let $\mu$ be the Lebesgue measure on $\R$.  Let \[
        \mathcal{L}^p([a,b]) = \{ \text{measurable } f: [a,b] \rightarrow \K \, | \, \int_a^b |f|^p \, d \mu < \infty \}
    \]
    
    Let $\| f \|_p = \left( \int_a^b |f|^p \, d \mu \right)^{1/p}$.  Since $\| f \|_p = 0 \iff f = 0 \, a.e$, we quotient out by the rule $f \equiv g \iff f - g = 0 \, a.e.$, and then our space of equivalence classes forms a normed vector space, denoted $L^p([a,b])$.
\end{exmp}

\begin{thm}[Riesz-Fischer] $(L^p([a,b]), \| \cdot \|_p )$ is the completion of $(\mathcal{C}[a,b], \| \cdot \|_p )$, and is a Banach space.
\end{thm}
\begin{proof}
    Properties of the Lebesgue integral.
\end{proof}

\begin{rem}{\ }
    \begin{itemize}
        \item Let $X$ be any compact topological space, let $\mathcal{C}(X) = \{ f : X \rightarrow \K \, | \, \text{$f$ is continuous} \}$, and let $\|f \|_\infty = \sup_{x \in X} \|f(x)|$.  Then $\mathcal{C}(X, \| \cdot \|_\infty)$ is Banach.  
        \item Let $X$ be any topological space.  Then the set of all continuous and bounded functions with the supremum norm forms a Banach space.
        \item Let $(S, \mathcal{A}, \mu)$ be a measure space.  Then we can define the $\mathcal{L}^p$ and $L^p$ analogously, and they are also Banach.
    \end{itemize}
\end{rem}

\begin{defn}[Linear operators on normed vector spaces]
    Let $X,Y$ be vector spaces over $\K$.  A linear operator is a function $T:X \rightarrow Y$ such that 
    \begin{align*}
        T(x+y) &= T(x) + T(y) \\
        T(\alpha x) &= \alpha T(x)
    \end{align*}
    for all $x,y,\alpha$.

    We write $\text{Hom}(X,Y) = \{ T: X \rightarrow Y \, | \, \text{$T$ is linear} \}$
\end{defn}

\begin{defn}[]
    $T: X \rightarrow Y$ is continuous at $x \in X$ if for all $\epsilon > 0$, there exists $\delta > 0$ such that \[
            \| x - y \|_X < \delta \Rightarrow \| Tx - Ty \|_y < \epsilon 
    \]
\end{defn}

\begin{defn}[]
    \[
    \mathcal{L}(X,Y) = \{ T:  X \rightarrow Y \, | \, \text{$T$ is linear and continuous} \}
    \]
\end{defn}

\begin{rem}
    If $\text{dim}(X) < \infty$ then $\text{Hom}(X,Y) = \mathcal{L}(X,Y)$.  This is \textbf{not} true if $X$ has infinite dimension.
\end{rem}

\begin{defn}[Bounded linear operator]
    Let $T: X \rightarrow Y$ be linear, then $T$ is \textbf{bounded} if $T$ maps bounded sets in $X$ to bounded sets in $Y$.  That is: for each $M > 0$ there exists $M' > 0$ such that \[
        \| x \|_X \leq M \Rightarrow \|Tx\|_Y \leq M'
    \]
\end{defn}
% section lecture_3_monday_7_march (end)

\section{Lecture 4 - Wednesday 9 March } % (fold)
\label{sec:lecture_4_}
Consider the space $\mathcal{L}(X, Y)$, the set of all linear and continuous maps between two normed vector spaces $X$ and $Y$.  

\begin{thm}[Fundamental theorem of linear operators]
    Let $( X, \| \cdot \|_X)$ and $Y, \| \cdot \|_Y$ be normed vector spaces.  Let $ T \in \text{Hom}(X,Y)$, the set of all linear maps from $X$ to $Y$.  Then the following are all equivalent.
    \begin{enumerate}[1)]
        \item $T$ is uniformly continuous
        \item $T$ is continuous
        \item $T$ is continuous at 0
        \item $T$ is bounded
        \item There exists a constant $c > 0$ such that \[
            \| Tx \|_Y \leq c \| x \|_X \quad \forall x \in X
        \]
    \end{enumerate}
\end{thm}

\begin{proof}
    $1) \Rightarrow 2) \Rightarrow 3)$ is clear.
    
    $3) \Rightarrow 4)$.  Since $T$ is continuous at 0, given $\epsilon = 1 > 0$, there exists $\delta$ such that \[
        \| Tx - T0 \| \leq 1 \quad \text{whenever} \quad \| X - 0 \| \leq \delta,
    \] i.e. that $\| x \leq \delta \Rightarrow \| Tx \| \leq 1$.  Let $y \in X$.  The $\| \frac{\delta y}{\| y \|} \| \leq \delta$, and so $\| T\left( \frac{\delta y}{\| y \|} \right) \| < \leq 1$.  Hence, \[
        \frac{\delta}{\|y \|} \|T y \| \leq 1
    \] and so \[
        \|Ty \| \leq \frac{ \| y \|}{\delta}
    \] for all $y \in X$.  Thus, for all $\| y \| \leq M$, we have $\| Ty \| \leq M'$, where $M' = \frac{M}{\delta}$, and so $T$ is \textbf{bounded.} 
    
    $4) \Rightarrow 5)$.  If $T$ is bonded, given $M = 1 > 0$, there exists $c \geq 0$ such that $\| x \| \leq 1 \Rightarrow \|T x \| \leq c$.  Then \[
         \|T \left( \frac{x}{\|x \|} \right) \| \leq c  \] 
        Hence, $\|Tx \| \leq c \| x \|$.  
        
    $5) \Rightarrow 1)$.  If $5)$ holds, then  \[
        \| Tx - Ty \| = \| T(x-y) \| \leq c \| x - y \|.
    \]  So if $\epsilon$ is given, taking $\delta = \frac{\epsilon}{c}$, we have \[
        \|Tx - Ty \| \leq c \| x - y \| < c \frac{\epsilon}{c} = \epsilon. \qedhere
    \]
\end{proof}

\begin{cor}
    If $T \in \text{Hom}(X,Y)$, then $T$ continuous $\iff$ $T$ bounded $\iff$ $\|Tx \| \leq c \| x \|$ for all $x \in X$.
\end{cor}

\begin{defn}[Operator norm]
    The \textbf{operator norm} of $T \in \mathcal{L}(x,y)$, $\| T\|$ is defined by any one of the following equivalent expressions.
    \begin{enumerate}[(a)]
        \item $\|T \| = \inf \{ c > 0 \, | \, \| Tx \| < c \| x \| \}$.
        \item $\| T\| = \sup_{x \neq 0} \frac{ \|Tx \|}{\| x \|}$.
        \item $\| T \| = \sup_{ \|x \| \leq 1} \| Tx \|$.
        \item $\| T \| = \sup_{\| x \| = 1} \|T x \|$.
    \end{enumerate}
\end{defn}

\begin{prop}
    The operator norm is a norm on $\mathcal{L}(x,y)$.  
\end{prop}

\begin{proof}  The following are simple to verify.
    \begin{enumerate}[(a)]
        \item $\| T \| \geq 0$, with equality if and only if $ T = 0$. 
        \item $\| \alpha T \| = | \alpha | \|T \|$.
        \item $\| S + T \| \leq  \| S \| + \| T \|$.
    \end{enumerate}
\end{proof}

\begin{exmp}[Calculating $\| T \|$]
    To calculate $\| T \|$, try the following. 
    \begin{enumerate}[1)]
        \item Make sensible calculations to find $c$ such that \[
            \| Tx \| \leq c \| x \|
        \] for all $x \in X$.
        \item Find $x \in X$ such that $\|Tx \| = c \| x \|$.
    \end{enumerate}
\end{exmp}
% section lecture_4_ (end)

\section{Lecture 5 - Tuesday 15 March} % (fold)
\label{sec:lecture_5_tusday_15_march}
\begin{rem}
    Ignore !2, Q3(b), Q8 on the practice sheet, as we will be ignoring Hilbert space theory for the time being.
\end{rem}

\begin{defn}[Algebraic dual]
    Let $(X, \| \cdot \|)$ be a normed vector space over $\K$.  The \textbf{algebraic dual} of $X$ is \[
        X^\star = \text{Hom}(X, \K) = \{ \phi: X \rightarrow \K \, | \, \text{$\phi$ is linear} \}.
    \]  Elements of $X^\star$ are called linear functionals.
\end{defn}

\begin{defn}[Continuous dual (just \textbf{dual})]
    The \textbf{continuous dual} (just dual) of $X$ is \[
        X' = \mathcal{L}(X, \K) = \{ \phi : X \rightarrow K \, | \, \text{$\phi$ is linear and continuous} \}.
    \]
\end{defn}

\begin{rem}
    $X^\star \supsetneq X'$ if $\dim(X) = \infty$.
\end{rem}

\begin{exmp}
    Let $(\wp([a,b]), \| \cdot \|_\infty)$ be the normed vector space of polynomials $p: [a,b] \rightarrow \K$.                 
    \begin{enumerate}[(a)]
        \item The functional $D : \wp([0,1]) \rightarrow \K$ given by $D(p) = p'(1)$ is linear, but \textbf{not} continuous.
        \item The functional $I: \wp([0,1]) \rightarrow \K$ given by $I(p) = \int_0^1 p(t) \, dt$ is linear \textbf{and} continuous.
    \end{enumerate}
\end{exmp}

\begin{proof}
\begin{enumerate}[(a)]
        \item Linearity is clear.  The $p_n(t) = t^n$ for all $t \in [0,1]$.  Then $|D(p_n)| =   n \| p_n \|_\infty$.  So $D$ is not continuous, as continuity implies that there exists $c$ such that \[
            \| Tx \| \leq c \| x \|.
        \]
        \item Exercise: Show $\| I \| = 1$.
\end{enumerate}
\end{proof}

Describing the continuous dual space $X'$ is one of the first things to do when trying to understand a normed vector space.  It is generally pretty difficult to describe $X'$.

\begin{prop}[Dual of the $\ell^p$ space for $(1 < p < \infty)$]
    Let $1 < p < \infty$.  Let $q$ be the ``dual'' of $p$, defined by $\frac{1}{q} + \frac{1}{p} = 1$.  Then $(\ell^p)'$ is isometrically isomorphic to $\ell^q$.  
\end{prop}
\begin{rem}[Observation before proof]
    Let $1 \leq p < \infty$.  Let $e_i = (0,0,\dots, 1, 0, \dots)$ where $1$ is in the $i$-th place.  
\begin{enumerate}[1)]
        \item If $x = (x_i) \in \ell^p$, then \[
            x = \sum_{i=1}^\infty x_i e_i
        \] in the sense that the partial sums converge to $x$.
        \item If $\phi : \ell^p \rightarrow \K$ is linear and continuous, then \[
            \phi(x) = \sum_{i = 1}^\infty x_i \phi(e_i)
        \]
\end{enumerate}

\begin{proof}[Proof of observations.]
    Let $S_n = \sum_{i=1}^n x_i e_i$.  Then \begin{align*}
        \| x - S_n \|_p^p &= \| (0,0,\dots, x_{n+1}, x_{n+2}, \dots) \|_p^p \\
        &= \sum_{i=n+1}^\infty |x_i|^p \\
        &\rightarrow 0 \quad \text{as it is the tail of a convergent sum.}
    \end{align*}
    
    Write $\phi(x)$ as \begin{align*}
        \phi(x) &= \phi( \lim_{n \rightarrow \infty} S_n)  \quad \text{(continuity)}\\
                &= \lim_{n \rightarrow \infty} \left( \phi(S_n ) \right) \\
                &= \lim_{n \rightarrow \infty} \phi \left( \sum_{i=1}^n x_i e_i \right) \\
                &= \lim_{n \rightarrow \infty} \sum_{i=1}^n x_i \phi(e_i) \quad \text{(linearity)}  \\
                &= \sum_{i=1}^\infty x_i \phi(e_i) \qedhere
    \end{align*}
\end{proof}
\end{rem}

\begin{proof}
    Define a map $\theta$ by \mapping{\theta}{\ell^q}{(\ell^p)'}{y}{\phi_y} where $\phi_y(x) = \sum x_i y_i$ for all $x \in \ell^p$. 
    
    \begin{enumerate}[(1)]
        \item $\phi_y$ is linear, as $\phi_y( x + x') = \phi_y(x) + \phi_y(x')$ (valid as sums converge absolutely.)
        \item $\phi_y$ is continuous, as \[
            | \phi_y(x) | = | \sum x_i y_i | \leq \sum | x_i y_i | \leq  \| x \|_p \| y \|_q
        \] by H\"older's inequality.  From the fundamental theorem of linear operators, as $| \phi_y(x) | \leq \| x \|_p \| y \|_q$, we have that $\phi_y$ is continuous, and that 
        \begin{equation}
            \| \phi_y \| \leq \| y \|_q \tag{$\star$}
        \end{equation}  
        \item $\theta$ is linear. 
        \item $\theta$ is injective, as \[
            \theta(y) = \theta(y') \Rightarrow \phi_y = \phi_{y'} \Rightarrow \phi_y(x) = \phi_{y'}(x)\quad \forall x \in \ell^p
        \] \[
            \Rightarrow \phi_y(e_i) = \phi_{y'}(e_i) \quad\forall i \in \N \Rightarrow y_i = y_i' \quad\forall i \in \N \Rightarrow y = y'
        \]
        \item $\theta$ is surjective.  Let $\phi \in (\ell^p)$.  Let $y = ( \phi(e_1), \dots, \phi(e_n), \dots) = (y_1, \dots, y_n, \dots)$.  We now show $y \in \ell^q$.  
        
        Let $x^{(n)} \in \ell^q$  be defined by \[
            x_i^{(n)} = \begin{cases}
                \frac{|y_i|^q}{y_i} &\text{if $i \leq n$ and $y_i \neq 0$} \\
                0 &\text{otherwise}
            \end{cases}
        \]
        Then \begin{equation}
            \phi( x^{(n)}) = \sum_{i=1}^\infty x_i^{(n)} \phi(e_i) = \sum_{i=1}^n |y_i|^q
            \tag{$\dagger$}
        \end{equation} by Observation 2) above. 
        
        On the other hand, we know \begin{align*}
            \| \phi( x^{(n)}) &\leq \| \phi \| \| x^{(n)} \|_p \\
                            &= \| \phi \| \left( \sum_{i=1}^\infty |x_i^{(n)}|^p \right)^{1/p} \\
                            &= \| \phi \| \left( \sum_{i = 1}^n |y_i |^{(q-1)p} \right)^{1/p} \\
                            &= \| \phi \| \left( \sum_{i=1}^n |y_i |^q \right)^{1/p} \quad \text{as $1/p + 1/q = 1$.} \tag{$\star \star$}
        \end{align*}
        Now, using $(\dagger)$ and $(\star \star)$, we have \[
             \sum_{i=1}^n |y_i|^q  \leq \| \phi \| \left( \sum_{i=1}^n | y_i |^q \right)^{1/p} 
        \] and so we must have \[
            \| y \|_q \leq \| \phi \| \tag{$\star \star \star$}
        \]
        and so $y \in \ell^q$.
        
        We also have, by $(\star \star)$,\[
            \| y \|_q \leq \| \phi_y \|
        \] 
        \item Finally, we show that $\theta$ is an isometry.  By $(\star)$ and $(\star \star \star)$, we have \[
            \| \theta(y) \| = \| \phi_y \| = \| y \|_q 
        \] as required.\qedhere
         
    \end{enumerate} 
\end{proof} 
% section lecture_5_tusday_15_march (end)

\section{Lecture 6 - Wednesday 16 March} % (fold)
\label{sec:lecture_6_wednesday_16_march}
How big is $X'$?  When is $X' \neq \{ 0 \}$?  Examples suggest that $X'$ is big with a rich structure.  

\subsection{The Hahn-Banach theorem} % (fold)
\label{sub:the_hahn_banach_theorem}
The Hahn-Banach theorem is a cornerstone of functional analysis.  It is all about extending linear functionals defined on a subspace to linear functionals on the whole space, while preserving certain properties of the original functional.

\begin{defn}[Seminorm]
A let $X$ be a vector space over $\K$.  A seminorm on $X$ is a function $p : X \rightarrow \R$ such that 
\begin{enumerate}[(1)]
    \item $p(x+y) \leq p(x) + p(y) \quad \forall x,y \in X$
    \item $p(\lambda x) = | \lambda | p(x) \quad \forall x \in X, \lambda \in \K$
\end{enumerate}
\end{defn}

\begin{thm}[General Hahn-Banach]
    Let $X$ be a vector space over $\K$.  Let $p: X \rightarrow \R$ be a seminorm on $X$.  Let $Y \subseteq X$ be a subspace of $X$.  If $f : Y \rightarrow \K$ is a linear functional such that \[
        | f(y) | \leq p(y) \quad \forall y \in Y
    \] then there is an extension $\tilde{f} : X \rightarrow \K$ such that 
    \begin{itemize}
        \item $\tilde{f}$ is linear
        \item $\tilde f (y) = f(y) \quad \forall y \in Y$
        \item $|f(x)| \leq p(x) \quad \forall x \in X$
    \end{itemize}
\end{thm}

\begin{rem}
    This is great.
    \begin{itemize}
        \item $Y$ can be finite dimensional (and we know about linear functionals on finite dimensional spaces)
        \item If $p(x) = \| x \|$, then \[
            |\tilde f (x) | \leq \|x \| \quad \forall x \in X
        \] and so $\tilde f \in X'$
    \end{itemize}
\end{rem}

\begin{cor}
    Let $(X, \| \cdot \|)$ be a normed vector space over $\K$.  For each $y \in X$, with $y \neq 0$, there is $\phi \in X'$ such that \[
        \phi(y) = \| y \| \quad \text{and} \quad \| \phi \| = 1
    \]
\end{cor}
\begin{proof}
    Fix $y \neq 0$ in $X$.  Let $Y = \{ \K y \} = \{ \lambda y | \lambda \in \K \}$, a one-dimensional subspace.  
    
    Define $f : Y \rightarrow \K$, $f( \lambda y) = \lambda \| y \|$.  This is linear.  Set $p(x) = \| x \|$.  Then \[
        | f(\lambda y ) = p(\lambda y)
    \] and so by Hahn-Banach, there exists $\tilde f : X \rightarrow \K$ such that
    \begin{itemize}
        \item $\tilde f$ is linear
        \item $\tilde f(\lambda y) = f( \lambda y) \quad \forall \lambda \in \K$
        \item $| \tilde f (x) | \leq \| x \| \quad \forall x \in X$
    \end{itemize}
    Then we  have $\tilde f \in X'$ and $\| f \| = 1$ as required.
\end{proof}

% subsection the_hahn_banach_theorem (end)

\subsection{Zorn's Lemma} % (fold)
\label{sub:zorn_s_lemma}

\begin{thm}[Axiom of Choice is equivalent to Zorn's Lemma]
    See handout for proof that \[
        A.C. \Rightarrow Z.L.
    \]
\end{thm}

\begin{defn}[Partially ordered set]
    A \textbf{partially ordered set} (poset) is a set $A$ with a relation $\leq$ such that 
    \begin{enumerate}[(1)]
        \item $ a \leq a$ for all $a \in A$,
        \item If $a \leq b$ and $b \leq a$then $a = b$,
        \item If $a \leq b$ and $b \leq c$, then $a \leq c$
    \end{enumerate}
\end{defn}

\begin{defn}[Totally ordered set]
    A \textbf{totally ordered set} is a poset $(A, \leq)$ such that if $a, b \in A$ then either $a \leq b$ or $b \leq a$.
\end{defn}

\begin{defn}[Chain]
    A \textbf{chain} in a poset $(A, \leq)$ is a totally ordered subset of $A$.
\end{defn}

\begin{defn}[Upper bound]
    Let $(A, \leq)$ be a poset.  An \textbf{upper bound} for $B \subseteq A$ is an element $u \in A$ such that $b \leq u$ for all $ b \in B$.  
\end{defn}

\begin{defn}[Maximal element]
    A \textbf{maximal element} of a poset $(A, \leq)$ is an element $m \in A$ such that $m \leq x$ implies $x = m$, that is, \[
        m \leq x \Rightarrow x = m
    \]
\end{defn}

\begin{exmp}
    Let $S$ be any set.  Let $\mathcal{P}(S)$ be the power set of $S$ (the set of all subsets of $S$).  Define $a \leq b \iff a \subseteq b$.  Maximal element is $S$
\end{exmp}

\begin{thm}[Zorn's Lemma]
    Let $(A, \leq)$ be a poset.  Suppose that every chain in $A$ has an upper bound.  Then $A$ has (at least one) maximal element.  
\end{thm}

\begin{exmp}[Application - all vector spaces have a basis]
    \begin{defn}[Linearly independent]
        Let $X$ be a vector space over $\F$.  We call $B \subseteq X$ \textbf{linearly independent} if \[
            \lambda_1 x_1 + \dots + \lambda_n x_n = 0 \Rightarrow \lambda_1 = \dots = \lambda_n = 0
        \] for all finite $\{ x_1, \dots, x_n \} \subseteq B$. 
    \end{defn}
    
    \begin{defn}[Span]
        We say $B \subseteq X$ \textbf{spans} $X$ if each $x \in X$ can be written as \[
            x = \lambda_1 x_1 + \dots + \lambda_n x_n
        \] for some $\lambda_1, \dots, \lambda_n \in \F$ and $\{ x_1, \dots, x_n \} \subseteq B$. 
    \end{defn}
    
    \begin{defn}[Hamel basis]
        A Hamel basis is a linearly independent spanning set. Equivalently, $B \subseteq X$ is a Hamel basis if and only if each $x \in X$ can be written in exactly one way as a finite linear combination of elements of $B$.
    \end{defn}
    
    \begin{thm}
        Every vector space has a Hamel basis
    \end{thm}
    
    \begin{proof}
        Let $L = \{ \text{linearly independent subsets} \}$, with subset ordering.  Let $C$ be a chain in $L$.  Let $u = \bigcup_{a \in C} a$.  Then 
        \begin{enumerate}[(1)]
            \item $u \in L$,
            \item $u$ is an upper bound for $C$.
        \end{enumerate}  
        So Zorn's Lemma says that $L$ has a maximal element $\mathbf{b}$.  
        
        Then $\mathbf{b}$ is a Hamel basis. 
        \begin{itemize}
            \item $\mathbf{b}$ is linearly independent.  
            \item If $\text{Span}(\mathbf{b}) \neq X$, there exists $X \in X \backslash \text{Span}(\mathbf{b})$, and $\mathbf{b'} = \mathbf{b} \bigcup \{ x \} \in L$ is linearly independent, contradicting maximality of $\mathbf{b}$.
        \end{itemize}  
    \end{proof}
    
    \begin{rem}
        If $ X, \| \cdot \| )$ is Banach, every Hamel basis is uncountable.
    \end{rem}
\end{exmp}
% subsection zorn_s_lemma (end)

% section lecture_6_wednesday_16_march (end)

\section{Lecture 7 - Monday 21 March} % (fold)
\label{sec:lecture_7_monday_21_march}
Proof of Hahn-Banach Theorem
Discussion of Dual operators

\begin{thm}[Hahn-Banach theorem over $\R$]
    Let $X$ be a real linear space and let $p(x)$ be a seminorm on $X$.  Let $M$ be a real linear subspace of $X$ and $f_0$ a real-valued linear functional defined on $M$.  Let $f_0$ satisfy $f_0(x) \leq p(x)$ on $M$.  Then there exists a real valued linear functional $F$ defined on $X$ such that 
    \begin{enumerate}[(i)]
        \item $F$ is an extension of $f_0$, that is, $F(x) = f_0(x)$ for all $x \in M$, and 
        \item $F(x) \leq p(x)$ on $X$.  
    \end{enumerate}
\end{thm}

\begin{proof}
    We first show that $f_0$ can be extended if $M$ has codimension one.  Let $x_0 \in X \backslash M$ and assume that $\text{span}(M \cup \{ x_0 \}) = X$. As $x_0 \notin M$ be can write $x \in X$ uniquely in the form \[
        x = m + \alpha x_0
    \] for $\alpha \in \R$.  Then for every $c \in \R$, the map $f_c \in \text{Hom}(X, \R)$ given by $f_c(m + \alpha x) = f_0(m) + c \alpha$ is well defined, and $f_c(m) = f_0(m)$ for all $m \in M$. We now show that we can choose $c \in \R$ such that $f_c(x) \leq p(x)$ for all $ x \in X$.  Equivalently, we must show 
    \[
        f_0(m) + c \alpha \leq p(m + \alpha x_0)
    \] for all $m \in M$ and $\alpha \in \R$.  By positive homogeneity of $p$ and linearity of $f$ we have \begin{align*}
        f_0(m / \alpha) + c &\leq p(x_0 + m/\alpha) \quad \alpha > 0 \\
        f_0(-m/\alpha) - c &\leq p(-x_0 -m/\alpha) \quad \alpha < 0
    \end{align*}  Hence we need to choose $c$ such that \begin{align*}
        c &\leq p(x_0 + m) - f_0(m) \\
        c &\geq -p(-x_0 + m) + f_0(m).
    \end{align*}  This is possible if \[
        -p(-x_0 + m_1) + f_0(m_1) \leq p(x_0 + m_2) - f_0(m_2) 
    \] for all $m_1, m_2 \in M$.  By subadditivity of $p$ we can verify this condition since \[
        f_0(m_1 + m_2) \leq p(m_1 m_2) = p(m_1 - x_0 + m_2 - x_0) \leq p(m_1 - x_0) + p(m_2 + x_0)
    \] for all $m_1, m_2 \in M$.  Hence $c$ can be chosen as required.
    
    
    Hence $D(F) = X$, and the theorem is proven.
\end{proof}


\begin{thm}[Hahn-Banach over $\Com$]
    Suppose that $c$ is a seminorm on a complex vector space $X$ and let $M$ sub a subspace of $X$.  If $f_0 \in \text{Hom}(M, \Com)$ is such that $|f_0(x) | \leq p(x)$ for all $x \in M$, then there exists an extension $f \in \text{Hom}(X, \Com)$ such that $f|_M = f_0$ and $|f(x)| \leq p(x)$ for all $x \in X$.  
\end{thm} 

\begin{proof}
    Split $f_0$ into real and imaginary parts \[
        f_0(x) = g_0(x) + ih_0(x).
    \]  By linearity of $f_0$ we have \begin{align*}
        0   &= if_0(x) - f_0(ix) = ig_0(x) - h_0(x) - g_0(ix) - ih_0(ix) \\
            &= -(g_0(ix) + h_0(x) ) + i(g_0(x) - h_0(ix))
    \end{align*} and so $h_0(x) = -g_0(ix)$.  Therefore, \[
        f_0(x) = g_0(x) - ig_0(ix)
    \] 
    for all $x \in M$.  We now consider $X$ as a vector space over $\R$, $X_\R$.  Now considering $M_\R$ as a subspace of $X_\R$.  GSince $g_0 \in \text{Hom}(M_\R, \R)$ and $g_0(x) \leq |f_0(x)| \leq p(x)$ and so by the real Hahn-Banach, there exists $g \in \text{Hom}(X_\R, \R)$ such that $g|_{M_\R} = g_0$ and $g(x) \leq p(x)$ for all $x \in X_\R$.  Now set $F(x) = g(x) - ig(ix)$ for all $x \in X_\R$.  Then by showing $f(ix) = if(x)$, we have that $f$ is linear.  
    
    We now show $|f(x)| \leq p(x)$.  For a fixed $x \in X$ choose $\lambda \in \Com$ such that $\lambda f(x) = |f(x)|$.  Then since $|f(x)| \in \R$ and by definition of $f$, we have \[
        |f(x)| = \lambda f(x) | = f(\lambda x) = g(\lambda x) \leq p(\lambda x) = |\lambda p(x) = p(x)
    \] as required.  
 \end{proof}
% section hahn_banac (end)
% section lecture_7_monday_21_march (end)

\section{Lecture 8 - Wednesday 23 March} % (fold)
\label{sec:lecture_8_wednesday_23_march}
\begin{defn}[Inner product]
    Let $X$ be a vector space over $\K$.  
    An \textbf{inner product} is a function \[
    \langle \cdot, \cdot \rangle : X \times X \rightarrow \K 
    \] such that 
    \begin{enumerate}[(1)]
        \item $\langle x + y, z \rangle = \langle x, z \rangle + \langle y, z \rangle$
        \item $\langle \alpha x, z \rangle = \alpha \langle x, z \rangle$
        \item $\langle x, y \rangle = \overline{ \langle y, x \rangle}$
        \item $\langle x, x \rangle \geq 0$ with equality if and only if $x = 0$
    \end{enumerate}
    We then have \[
        \langle x, y + z \rangle = \langle x, y \rangle + \langle x, z \rangle
    \] and \[
        \langle x, \alpha z \rangle = \overline \alpha \langle x, z \rangle
    \]
\end{defn}

\begin{defn}[Inner product space]
    Let $(X, \langle \cdot, \cdot \rangle)$ be an \textbf{inner product space}.  Defining $\| x \| = \sqrt{ \langle x, x \rangle}$ turns $X$ into a normed vector space.  To prove the triangle inequality, we use the Cauchy-Swartz theorem.
\end{defn}

\begin{thm}[Cauchy-Schwarz]
    In an inner product space $(X, \langle \cdot, \cdot \rangle)$, we have \[
        | \langle x, y \rangle | \leq \|x \| \| y \| \quad \forall x, y  \in X
    \] 
\end{thm}
\begin{proof}
    \begin{align*}
        0   &\leq \langle x - \lambda y, x - \lambda y \rangle \\
            &= \langle x, x \rangle - \langle x, \lambda y \rangle - \langle \lambda y, x \rangle +\langle \lambda y, \lambda y \rangle  \\
            &= \| x \|^2 - \bar \lambda \langle x, y \rangle - \lambda \langle y, x \rangle + |\lambda|^2 \| y \|^2 \\
            &= \| x \|^2 - 2 \Re ( \lambda \langle y, x \rangle ) + |\lambda|^2 \| y \|^2 \\
    \end{align*}  Set $\lambda = \frac{\langle x, y \rangle}{\| y \|^2}$.  Then
    \begin{align*}
        0 &\leq \| x \|^2 - 2 \Re ( \frac{|\langle x, y \rangle|^2}{\| y \|^2} ) + \frac{|\langle x, y \rangle|^2}{\| y \|^2} \\
            &= \| x \|^2 - \frac{|\langle x, y \rangle|^2}{\| y \|^2}
    \end{align*} as required.
\end{proof}

\begin{cor}
    \[
        \| x + y \| \leq \| x \| + \| y \|
    \]
\end{cor}

\begin{defn}[Hilbert space]
    If $(X, \langle \cdot, \cdot \rangle)$ is complete with respect to $\| \cdot \|$ then it is called a \textbf{Hilbert space.} 
\end{defn}

\begin{exmp}
    \begin{enumerate}[(a)]
        \item $\ell^2$, where $\langle x, y \rangle = \sum_{i=1}^\infty x_i \overline{y_i}$.  
        
        Cauchy-Schwarz then says \[
            | \sum_{i=1}^\infty x_i \overline{y_i} | \leq \sqrt{ \sum_{i=1}^\infty |x_i|^2} \sqrt{\sum_{i=1}^\infty |y_i|^2}
        \]
        \item $L^2([a,b])$, where $\langle f, g \rangle = \int_a^b f(x) \overline{g(x)} \, dx$. 
        
        Cauchy-Swartz then says \[
            | \int_a^b f(x) \overline{ g(x)} \, dx \leq .....
        \]
    \end{enumerate}
\end{exmp}

\begin{defn}[Orthogonality]
    Let $(X, \langle \cdot , \cdot \rangle )$ be inner product spaces.  Then $x, y \in X $ are orthogonal if $\langle x, y \rangle = 0$ where $x, y \neq 0$.  
\end{defn}

\begin{thm}
    Let $x_i, \dots, x_n$ be pairwise orthogonal elements in $(X, \langle \cdot , \cdot \rangle)$.  Then \[
        \| \sum_{i=1}^n x_i \|^2 = \sum_{i=1}^n \|x_i\|^2
    \]
\end{thm}

\begin{thm}[Parallelogram identity]
    In $(X, \langle \cdot, \cdot \rangle)$ we have \[
         \| x+ y \|^2 + \| x-y \|^2 = 2( \| x \|^2 + \|y \|^2) \tag{$\star$}
    \] for all $x, y \in X$.
\end{thm}

\begin{rem}
    If $(X, \| \cdot \|)$ is a normed vector space which satisfies parallelogram identity then $X$ is an inner product space with inner products defined by the polarisation equation \[
    \langle x, y \rangle =  \begin{cases} 
            \frac{1}{4} \left( \| x + y \|^2 - \| x - y \|^2 \right)    & \K = \R \\
            \frac{1}{4}\left( \| x + y\|^2 - \| x - y \|^2 + i\| x + iy \|^2 - i\|x - iy\|^2 \right)                                                & \K = \Com
        \end{cases}
    \]
\end{rem}

\begin{defn}[Projection]
    Let $X$ be a vector space over $\K$.  A subset $M$ of $X$ is convex if for any $x, y \in M$, then \[
        tx + (1-t) y \in M \quad \forall t \in [0,1]
    \]
\end{defn}

\begin{thm}[Projection]
    Let $(\Hil, \langle \cdot, \cdot, \rangle )$ be a Hilbert space.  Let $M \subseteq \Hil$ be closed and convex.  Let $x \in \Hil$.  Then there exists a unique point $m_x \in M$ which is closest to $x$, i.e. \[
        \| x - m_x \| = \inf_{m \in M} \| x - m \| = d
    \]  
\end{thm}

\begin{proof}
    For each $k \geq 1$ choose $m_k \in M$ such that \[
        d^2 \leq \| x - m_k \|^2 \leq d^2 + \frac{1}{k} 
    \] Each $m_k$ exists as $d$ is defined as the infimum over all $m$. 
    
    Then \begin{align*}
        \| m_k - m_l \|^2   &= \| (m_k - x) - (m_k - x) \|^2 \\
                            &= 2 \| m_k - x \|^2 + 2 \| m_l - x \|^2 - \| m_k + m_l - 2x \|^2 \\
                            &\leq 2d^2 + \frac{2}{l} + 2d^2 + \frac{2}{k} - 4 \| \frac{ m_k + m_l}{2} - x \|^2 \\
    \end{align*} and as $m_k/2 + m_l/2 \in M$, we have $\| \frac{ m_k + m_l}{2} - x \|^2  \geq d^2$.  Then 
    \begin{align*}
            \| m_k - m_l \|^2 \leq 2 ( \frac{1}{k} + \frac{1}{l})
    \end{align*} Thus $(m_k)$ is Cauchy.  So $m_k \rightarrow m_x \in M$ as $\Hil$ is complete and $M$ is closed.  We then have \[
        \| x - m_x \| = d 
    \] and so now we show that $m_x$ is unique.  
    
    Suppose that there exists $m'_x \in M$ with $\| x - m'_x \| = d$.  Then by the above inequality, we have \[
        \| m_x - m'_x \|^2 = 2 \| m_x - x \|^2 + 2 \| m'_x - x \|^2 - 4 \| \frac{m_x - m'_x}{2} - x \|^2 \leq 0 
    \] from above. 
\end{proof}

\begin{defn}[Projection operator]
Let $\hilb$ be a Hilbert space.  Let $M \subseteq \Hil$ be closed and convex.  Define \[
    P_M : \Hil \rightarrow \Hil
\] by $P_M(x) = m_x$ from above. This is the projection of $\Hil$ onto $M$.
\end{defn}

\begin{defn}[Orthogonal decomposition]  
    If $S \subseteq \Hil$, let \[
        S^\perp = \{ x \in \Hil
 \, | \langle x, y \rangle = 0 \quad \forall y \in S. 
\] We call $S^\perp$ the orthogonal component.
\end{defn}

% section lecture_8_wednesday_23_march (end)

\section{Lecture 9 - Monday 28 March} % (fold)
\label{sec:lecture_9_monday_28_march}

\begin{thm}[From previous lecture]
    If $M \subseteq \Hil$, then the projection of $\Hil$ onto $M$ is \mapping{P_m}{\Hil}{\Hil}{x}{m_x} where $m_x \in M$ is the unique element with $\| x - m_x \| = \inf_{m \in M} \| x - m \|$.  
\end{thm}

\begin{lem}
    Let $M \subseteq \Hil$ be closed subspace.  Then $x - P_M x \in M^{\perp}$ for all $x \in \Hil$.
\end{lem}

\begin{proof}
    Let $m \in M$.  We need to show $\langle x - P_M x , m \rangle = 0$.  This is clear if $m = 0$.  Without loss of generality, assuming $ m \neq 0$, we can assume $ \| m \| = 1$.  Then write \[
        x - P_M x = x - \left( P_M x + \langle x - P_M x, m \rangle m \right) + \langle x - P_M x, m \rangle m.
    \]   Let the bracketed term be $m'$.  Then $ x- m' \perp \langle x - P_M x, m \rangle m$ because 
    \begin{align*}
        \langle x - m', \langle x - P_M x, m \rangle m \rangle &= \overline{\langle x - P_M x, m \rangle} \langle x - m', m \rangle \\
        &= C \langle x - P_M x - \langle x - P_M x, m \rangle m, m \rangle \\
        &= C( \langle x - P_M x, m \rangle - \langle x - P_M x, m \rangle \| m \|) \\
        &= 0.
    \end{align*}
    
    So $\| x - P_M x \|^2 = \| x - m' \|^2 + | \langle x - P_M x, m \rangle |^2$.  So $\| x - P_M x \|^2 \geq \| x - P_M x\|^2 + | \langle x - P_M x, m \rangle |^2$ by definition of $P_M x$.  Thus, \[
        \langle x - P_M x, m \rangle = 0 
    \] and thus $x - P_M x \in M^\perp$.
\end{proof}

\begin{thm}
    The following theorem is the key fundamental result.  
    Let $\hilb$ be a Hilbert space.  Let $M$ be a closed subspace of $\Hil$.  Then \[
         \Hil = M \oplus M^\perp.
    \]  That is, each $x \in \Hil$ can be written in exactly one way as $x = m + m^\perp$ with $m \in M$, $m^\perp \in M^\perp$. 
\end{thm}

\begin{proof}
    \textbf{Existence} - Let $x = P_m x + ( x - P_M x)$. 
    
    \textbf{Uniqueness} - Let $x = x_1 + x_1^\perp$, $x = x_2 + x_2^\perp$ with $x_1, x_2 \in M, x_1^\perp, x_2^\perp \in M^\perp$
.  Then \[
    x_1 -x_2 = x^\perp_2 - x_1^\perp \in M^\perp
\] Then \[
    \langle x_1 - x_2, x_1 - x_n \rangle = 0 \Rightarrow x_1 = x_2 .  
\] Thus $x_1^\perp = x_2^\perp$.
\end{proof} 

\begin{cor}
    Let $M \subseteq \Hil$ be a closed subspace.  Then we have
    \begin{enumerate}[(a)]
        \item $P_M \in \mathcal{L}(\Hil, \Hil)$.
        \item $\| P_M \| \leq 1$.
        \item $\text{Im}P_m = M, \ker P_M = M^\perp$.
        \item $P^2_M = P_M$.
        \item $P_{M^\perp} = I - P_M$.
    \end{enumerate} 
\end{cor}
\begin{proof}
    (c), (d), (e) exercises.  
    
    (a).  Let $x,y \in H$.  Write $x = x_1 + x^\perp_1$ and $y = y_1 + y_1^\perp$ with $x_1, y_1 \in M$ and $x_1^\perp, y_1^\perp \in M^\perp$.  Then \[
        x = y = (x_1 + y_1) + (x^\perp_1 + y^\perp_1)
    \] and so \[
        P_M(x+y) = x_1 + y_1
    \] and similarly $P_M(\alpha x) = \alpha P_M x$.  We also have 
    \begin{align*}
        \| x \|^2   &= \|P_M x + (x - P_M x) \|^2 \\
                    &= \| P_M x \|^2 + \| x - P_M x \|^2 \\
                    \geq  \| P_M x \|^2 
    \end{align*} and so $\| P_M \| \leq 1$.  
\end{proof}

\subsection{The dual of a Hilbert space} % (fold)
\label{sub:the_dual_of_a_hilbert_space}

If $y \in \Hil$ is fixed, then the map \mapping{\phi_y}{\Hil}{\K}{x}{\langle x, y \rangle} is in $\Hil'$.  Linearity is clear, and continuity is proven by Cauchy-Swartz, \[
    | \phi_y(x) | = | \langle x, y \rangle | \leq \| y \| \| x \|.
\] So $\| \phi_y \| \leq \| y \|$. Since $|\phi_y(y)| = \| y \|^2$, we then have \[
    \| \phi_y \| = \| y \|.
\]

\begin{thm}[Riesz Representation Theorem]
    Let $\Hil$ be a Hilbert space. The map \mapping{\theta}{\Hil}{\Hil'}{y}{\phi_y} is a conjugate linear bijection, and $\| \phi_y \| = \| y \|$.  
\end{thm}
\begin{proof}
    Conjugate linearity is clear.
    
    \textbf{Injectivity} 
    \begin{align*}
        \phi_y = \phi_{y'} \Rightarrow \phi_y(x) = \phi_{y'}(x) \quad \forall x
    \end{align*} so \[
        \langle x, y = \langle x, y' \rangle  = 0 \quad \Rightarrow \langle y - y', y - y' \rangle = 0
    \] and so $y = y'$.
    
    \textbf{Surjectivity}
    Let $\phi \in H'$.  We now find $y \in \Hil$ with $\phi = \phi_y$.  If $\phi = 0$, take $y = 0$.  Suppose $\phi \neq 0$.  Then $\ker \phi \neq \Hil$.  But $\ker \phi$ is a closed subspace of $\Hil$.  So \[
        H = (\ker \phi) \oplus (\ker \phi)^\perp.
    \] Hence $(\ker \phi)^\perp \neq \{ 0 \}$. Pick $z \in (\ker \phi)^\perp, z \neq 0$.  For each $x \in \Hil$, the element \[
        x - \frac{\phi(x)}{\phi(z)} z \in \ker \phi
    \] Note that $\phi(z) \neq 0$ since $z \notin \ker \phi$.  Then \begin{align*}
        0   &=  \langle x - \frac{\phi(x)}{\phi(z)}z, z \rangle \\
            &= \langle x, z - \frac{\phi(x}{\phi(z)} \| z \|^2
    \end{align*}
    and so \[
    \phi(x) = \langle x, \frac{\overline{\phi(z)}}{\| z \|^2} z \rangle \quad \forall x \in \Hil,\]
    and so letting $y = \frac{\overline{\phi(z)}}{\| z \|^2} z$, we have $\phi = \phi_y$.  
\end{proof}

\begin{exmp}
    From Hahn-Banach given $y \in \Hil$ there exists $\phi \in \Hil'$ such that \[
        \| \phi \| = 1
    \] and $\phi(y) = \| y \|$. We can be very constructive in the Hilbert case, and let \[
        \phi(x) = \langle x, \frac{y}{\| y \|} \rangle
    \] 
\end{exmp}
\begin{exmp}
    All continuous linear functionals on $L^2([a,b])$ are of the form \[
        \phi(f) = \int_a^b f(x) \overline{g(x)} \, dx 
    \] for some $g \in L^2([a,b])$.
\end{exmp}

\begin{exmp}[Adjoint operators]
    Let $\Hil_1, \Hil_2$ be Hilbert spaces.  Let $ T \in \mathcal{L}(\Hil_1, \Hil_2)$.  The \textbf{adjoint} of $T$ is $T^\star \in \mathcal{L}(\Hil_2, \Hil_1)$ given by \[
        \langle T x, y \rangle_2 = \langle x, T^\star y \rangle_1
    \] for all $x \in \Hil_1, y \in \Hil_2$
\end{exmp}

\begin{exer}
    Check all of the above.
\end{exer}

\begin{exer}
    Prove $T^\star = \overline{T^t}$ where $T^t$ is the transpose.   
\end{exer}
% subsection the_dual_of_a_hilbert_space (end)
% section lecture_9_monday_28_march (end)

\section{Lecture 10 - Wednesday 30 March} % (fold)
\label{sec:lecture_10_wednesday_30_march}

\begin{defn}[Orthonormal system]
    As subset $S \subseteq \Hil$ is an \textbf{orthonormal system} (orthonormal) if \[
        \langle e, e' \rangle = \delta_{e, e'} \quad \forall e, e' \in S
    \]
\end{defn}

\begin{defn}[Complete orthonormal system or Hilbert basis]
    An orthonormal system $S$ is \textbf{complete} or a \textbf{Hilbert basis} if \[
        \overline{\spans S} = \Hil
    \]
\end{defn}

\begin{rem}
    By Gram-Schmidt and Zorn's Lemma, every Hilbert space has a complete orthonormal system.   
\end{rem}

\begin{exmp}
    \begin{enumerate}
        \item $\ell^2$.  Then \[
            S = \{ e_i \, | \, i \geq 1 \}
        \] is orthonormal and is complete.  
        \item $L^2_\Com([0, 2 \pi])$.  Then \[
            S = \{ \frac{1}{2\pi} e^{i n t} \, | \, n \in \Z \}
        \] is orthonormal and is complete.  Completeness follows from Stone-Weierstrass theorem.
        \item $L^2_\R([0, 2 \pi])$.  Then \[
            S= \{ \frac{1}{\sqrt{2\pi}}, \frac{1}{\sqrt{\pi}} \cos nt, \frac{1}{\sqrt{\pi}} \sin nt \, | \, n \geq 1 \}
        \] is orthonormal and is complete, again by Stone-Weierstrass.  
    \end{enumerate}
\end{exmp}

    We want to look at series $\sum_{e \in S} ...$, which is tricky if $S$ is not countable.

\begin{lem}\label{lem:tod}
    If $\{ e_k \, | \, k \geq 0 \}$ is orthonormal, then \[
        \sum_{k=0}^\infty a_l e_k
    \] converges in $\Hil$ if and only if \[
        \sum_{k=0}^\infty |a_k |^2
    \] converges in $\K$.  
    
    If either series converges, then \[
        \left\| \sum_{k=0}^\infty a_k e_k \right\|^2 = \sum_{k=0}^\infty | a_k |^2
    \]
\end{lem}

\begin{note}
    If $x_n \rightarrow x,y_n \rightarrow y$, then \[
        \langle x_n, y_n \rangle \rightarrow \langle x, y \rangle
    \]
\end{note}


\begin{proof}
    If $\sum_{k=0}^\infty a_k e_k$ converges to $x$, then \begin{align*}
        \langle x, x \rangle &= \lim_{n \rightarrow \infty} \langle \sum_{k=0}^n a_k e_k, \sum_{k=0}^n a_k e_k \rangle \\
        &= \lim_{n \rightarrow \infty} \sum_{k=0}^n | a_k |^2
    \end{align*}
    
    Conversely, if $\sum_{k=0}^\infty |a_k |^2$ converges, then writing $x_n = \sum_{k=0}^n a_k e_k$, we have \begin{align*}
        \| x_m - x_n \|^2 &= \| \sum_{k=n+1}^m a_k e_k \|^2 \\
                        &= \sum_{k=n+1}^m \| a_k e_k \|^2 \, \text{by Pythagoras} \\
                        &= \sum_{k=n+1}^m |a_k |^2 \rightarrow 0
    \end{align*} and so $(x_n)$ is Cauchy, and hence converges by completeness of $\Hil$.  
\end{proof}

\begin{lem}
    Let $\{ e_1, \dots, e_n \}$ be orthonormal. Then \[
        \sumkn | \iprod{x, e_k} |^2 \leq \|x\|^2 
    \] for each $x \in \Hil$.  
\end{lem}
\begin{proof}
    Let $y = \sumkn \iprod{x, e_k} e_k$.  Let $z = x-y$.  We claim that $z \perp y$.  We have 
    \begin{align*}
        \iprod{x,y} &= \iprod{x-y, y} \\
                    &= \iprod{x,y} - \| y \|^2 \\
                    &= \sumkn \overline{\iprod{x,e_k}} \iprod{x, e_k} - \sumkn | \iprod {x, e_k} |^2 \\
                    &= 0.
    \end{align*}
    So \begin{align*}
        \| x \|^2   &= \|y + z \|^2 \\
                    &= \| y \|^2 + \| z \|^2 \, \text{Pythagoras} \\
                    &\geq \|y \|^2 = \sumkn | \iprod{x, e_k} |^2
    \end{align*} 
\end{proof}

We want to write expressions like $\sum_{e \in S} \iprod{x, e} e$.
\begin{cor}
    Let $x \in \Hil$ and $S$ orthonormal.  Then \[
        \{ e \in S \, | \, \iprod{x, e} \neq 0 \}
    \] is countable.  
\end{cor}

\begin{proof}
    \[
        \{ e \in S \, | \, \iprod{x, e} \neq 0 \} = \bigcup_{k \geq 1} \{ e \in S \, | \, |\iprod{x, e} | > \frac{1}{k}
    \] From the lemma, \[
        \# \{ e \in S \, | \, | \iprod{x,e} | > \frac{1}{k} \} \leq k^2 \| x ^2 \|
    \] For if this number were greater than $k^2 \| x \|^2$, then the LHS in Lemma is greater than $\frac{1}{k^2}k^2 \| x \|^2$.  
\end{proof} 

Therefore:
\begin{cor}[Bessel's Inequality]
    If $S$ is orthonormal, then \[
        \sum_{e \in S} | \iprod{x,e}|^2 \leq \| x \|^2
    \] for all $x \in \Hil$
\end{cor}
\begin{proof}
    $\sum_{e \in S} | \langle x, e \rangle|^2$ is a sum of countably many positive terms, and so order is not important.
\end{proof}

We want to write $\sum_{e \in S} \iprod{x,e} e$.  This sum is over a countable set, but is the order important?

\begin{thm}
    Let $S$ be orthonormal.  Let $M = \overline{\spans S}$.  Then \[
        P_M x = \sum_{e \in S} \iprod{x,e} e
    \] where the sum can be taken in any order.
\end{thm}
\begin{proof}
    Fix $x \in H$.  Choose an enumeration $$\{ e_k \, | \, k \geq 0 \} = \{ e \in S \, | \, \iprod{x,e} \neq 0 \}.$$
    
    By Bessel's inequality, we have \begin{align*}
        \sum_{k=0}^\infty | \iprod{x, e_k} |^2 \leq \| x \|^2
    \end{align*} and so the LHS converges.  By Lemma~\ref{lem:tod}, we know \[
        y = \sum_{ k = 0}^\infty \iprod{x,e_k} e_k \in M
    \] converges in $\Hil$.  
    
    Write $x = y + (x-y) = M + M^\perp$.  We claim $(x-y) \in M^\perp$.  Then $P_Mx = y$ from characterisation of projection operator.  Let $e \in S$.  Then \begin{align*}
        \iprod{x-y, e} &= \lim_{n \rightarrow \infty} \iprod{ x - \sum_{k=0}^n \iprod{x, e_k} e_k, e} \\    
        &= \lim_{n \rightarrow \infty} ( \iprod{x,e} - \sum_{k=}^n \iprod{x, e_k} \iprod{e_k, e}) \\
        &= \iprod{x,e} - \sum_{k=0}^\infty \iprod{x, e_k} \iprod{e_k, e}.
    \end{align*}
    If $e \in \{ e' \in S \, | \, \iprod{x, e'} \neq 0 \}$, then $e = e_j$ for some $j$, and so \[
        \iprod{x-y, e} = \iprod{x, e_j} - \iprod{x, e_j} = 0
    \]  
    If $\iprod{x,e} = 0$, then $e \neq e_j$ for all $j$, and so $\iprod{e_j, e} = 0$, and so \[
        \iprod{x-y, e} = 0 - 0 = 0.
    \]
    
    Thus $x-y \in (\spans S)^\perp$.
    
    \begin{exer}
        Show that \[
            x-y \in \overline{(\spans S)}^\perp = M^\perp.
        \]
    \end{exer}
\end{proof}

% section lecture_10_wednesday_30_march (end)

\section{Lecture 11 - Monday 4 April} % (fold)
\label{sec:lecture_11_monday_4_april}
Recall that if $\{ x_1. \dots \}$ is a countable orthonormal system in a Hilbert space $\Hil$.  Then \[
    \sum_{k=1}^\infty a_k e_k < \infty \iff \sum_{k=1}^\infty |a_k|^2 < \infty 
\] and \[
    \| \sum_{k=1}^\infty a_k e_k \|^2 = \sum_{k=1}^\infty |a_k|^2 \tag{$\star$}
\] We also had the following.

\begin{thm}\label{thm:fourier}
    Let $S$ be orthonormal in $\Hil$.  Let $M = \overline{\spans S}$.  Then \[
        P_Mx = \sum_{e \in S} \iprod{x, e} e \quad \forall x \in \Hil
    \] where the sum has only countable many terms and convergence is unconditional.
\end{thm}

\begin{thm}
    Let $S$ be orthonormal in $\Hil$.  Then following are equivalent.
    \begin{enumerate}[(a)]
        \item $S$ is a complete orthonormal system ($\overline{\spans S} = \Hil$).
        \item $x = \sum_{e \in S} \iprod{x,e} e$ for all $x$ (Fourier series).
        \item $\| x \|^2 = \sum_{e \in S} |\iprod{x,e}|^2$ for all $x$ (Parseval's formula).
    \end{enumerate}
\end{thm}

\begin{proof}
    (a) $\Rightarrow$ (b).  If $M = \overline{\spans S} = \Hil$, then \[
        P_M x = x = \sum_{e \in S} \iprod{x,e} e
    \] by Theorem~\ref{thm:fourier}.
    
    (b) $\Rightarrow$ (c).  By the infinite Pythagoras theorem $(\star)$.  
    
    (c) $\Rightarrow$ (a).  Let $M = \overline{\spans S}$. Suppose that $z \in M^\perp$.  Then $z = 0 + z \in M + M^\perp$.  Hence \[
        0 = \| P_M z \|^2 = \|\sum_{e \in S} \iprod{z,e} e \|^2 = \sum_{e \in S} |\iprod{z,e} |^2 = \| z \|^2 
    \] which implies $z = 0$, so $M = \Hil$, and so $S$ is complete.
\end{proof}

\begin{rem}
    Consider $L^2([0,2\pi])$, and let $S = \{ e_n \, | \, n \in Z \}$.  Then we can write \[
         f = \sum_{ n \in \Z} c_n e_n
    \] where $c_n = \iprod{f,e_n} = \frac{1}{\sqrt{2 \pi}} \int_0^{2\pi} f(t) e^{-in t} \, dt$.  
    
    We do not claim that convergence is pointwise, what we have proven is convergence is in $L^2$, \[
        \| f - \sum_{|n| \leq N} c_n e_n \|_2 \rightarrow 0
    \] as $N \rightarrow \infty$.  This is not the same as pointwise or uniform convergence ($\| \cdot \|_\infty$).  
\end{rem}

\subsection{Stone-Weierstrass theorem} % (fold)
\label{sub:stone_weierstrass_theorem}
This is a useful tool to show an orthonormal system is complete.  In fact, this theorem is about uniformly approximating elements of $\mathcal{C}(X)$, where $X$ is a compact Hausdorff space.  it is a generalisation of the Weierstrass approximation theorem.

\begin{thm}[Weierstrass approximation theorem]
    Let $f \in \mathcal{C}([a,b])$ and let $\epsilon > 0$ be given.  Then there exists a polynomial $p(x)$ such that \[
        |f(x) - p(x) | < \infty \quad \forall x \in [a,b],
    \] that is, $\| f - p \|_\infty < \epsilon$.
    
    
\end{thm}
\begin{cor}  This implies the following important results:
    \begin{itemize}
        \item Continuous functions can be uniformly approximated by polynomials.  
        \item $\mathcal{P}([a,b])$, the space of polynomials on $[a,b]$, is dense in $\mathcal{C}([a,b])$.
        \item $\overline{\mathcal{P}([a,b])} = \mathcal{C}([a,b])$.   
    \end{itemize}
\end{cor}

We now prove Stone's 1930's generalisation.

\textbf{First some setup:} Let $X$ be a compact Hausdorff space throughout.  We then know that $\mathcal{C}(X)$ is a vector space.  It also has sensible vector multiplication, \[
    (fg)(x) = f(x) g(x).
\] Thus $\mathcal{C}(X)$ is a unital, commutative, associative ring.  As we have \[
    f(\lambda g) = \lambda (fg)
\] then $\mathcal{C}(X)$ is a unital, commutative, associative algebra over $\K$.  

\begin{defn}[Subalgebra] A subalgebra of $\mathcal{C}(X)$ is a subset $\mathcal{A}$ which is closed under scalar multiplication, vector addition, and vector multiplication.  $\mathcal{A}$ is unital if it contains the constant function $f(x) = 1$.  
\end{defn}

\begin{exmp}
    $\mathcal{P}([a,b])$ is a subalgebra of $\mathcal{C}([a,b])$.  
\end{exmp}

When is $\mathcal{A}$ dense in $\mathcal{C}(X)$?

\begin{thm}[Stone-Weierstrass theorem]
    Let $X$ be a compact Hausdorff space, and let $\mathcal{A}$ be a subalgebra of $\mathcal{C}(X)$. If 
    \begin{enumerate}[(1)]
        \item $\mathcal{A}$ is unital,
        \item $f \in \mathcal{A} \Rightarrow f^\star \in \mathcal{A}$, where $f^\star(x) = \overline{f(x)}$,
        \item $\mathcal{A}$ separates points of $X$.
    \end{enumerate}
    Then $\overline{\mathcal{A}} = \mathcal{C}(X)$. 
\end{thm}

\begin{defn}
    $\mathcal{A}$ separates points of $X$ if, given $x \neq y$, there is a function $f \in \mathcal{A}$ with $f(x) \neq f(y)$.  
\end{defn}
\begin{cor}
    \begin{enumerate}[(a)]
        \item $\mathcal{P}([a,b])$ is dense in $\mathcal{C}([a,b])$, as $f(x) = x$ separates points.  
        \item Trigonometric polynomials are dense in \[
            \{ f \in \mathcal{C}([0,2 \pi]) \, | \, f(0) = f(2 \pi) \}. 
        \]
        \item Trigonometric polynomials are dense in $L^2([0,2\pi])$, and \[
            S = \{ e_n \given n \in \Z \} 
        \] is complete.
    \end{enumerate}
\end{cor}

\textbf{Setup}
\begin{lem}
    The function $f(t) = |t|$ can be uniformly approximated by polynomials on $[-1,1]$  
\end{lem}
\begin{proof}
    The binomial theorem says \[
        (1 + x)^{1/2} = \sum_{n=0}^\infty {\frac{1}{2} \choose n} x^n \quad \forall x \in [-1,1]
    \]  We then have 
\begin{align*}
    |t | = \sqrt{t^2} = \sqrt{1 + (t^2 -1)} = \sum_{n=0}^\infty {\frac{1}{2} \choose n } (t^2 - 1)^n \quad t \in [-\sqrt{2}, \sqrt{2}]
\end{align*}

Now let $p_N(t) = sum_{n=0}^N {\frac{1}{2} \choose n } (t^2 - 1)^n$, and \[
    | |t| -p_N(t) | = | \sum_{n = N+1}^\infty { \frac{1}{2} \choose n}(t^2 - 1)^n | \leq \sum_{n = N+1}^\infty | {\frac{1}{2} \choose n} |
\] and so $\| |t| - p_n \|_\infty \rightarrow 0$ as $N \rightarrow \infty$ on $[-1,1]$.
\end{proof}


% subsection stone_weierstrass_theorem (end)
% section lecture_11_monday_4_april (end)

\section{Lecture 12 - Wednesday 6 April} % (fold)
\label{sec:lecture_12_wednesday_6_april}
\begin{thm}[Stone-Weierstrass theorem]
    Let $X$ be a compact Hausdorff space, and let $\mathcal{A}$ be a subalgebra of $\mathcal{C}(X)$. If 
    \begin{enumerate}[(1)]
        \item $\mathcal{A}$ is unital,
        \item $f \in \mathcal{A} \Rightarrow f^\star \in \mathcal{A}$, where $f^\star(x) = \overline{f(x)}$,
        \item $\mathcal{A}$ separates points of $X$.
    \end{enumerate}
    Then $\overline{\mathcal{A}} = \mathcal{C}(X)$. 
\end{thm}
\begin{proof}
    We first prove for $\mathcal{C}_\R(X)$. 
    
    \begin{lem}
        Let $\mathcal{A}$ be a unital subalgebra of $\mathcal{C}_\R(X)$ . Then \begin{enumerate}[(a)]
            \item $|f| \in \overline{\mathcal{A}}$,
            \item $\min(f_1, \dots, f_n), \max(f_1, \dots, f_n) \in \overline{\mathcal{A}}$ 
        \end{enumerate} for all $f, f_1, \dots, f_n \in \mathcal{A} \subseteq \mathcal{C}_\R(X)$. 
    \end{lem}
    \begin{proof}
        \begin{enumerate}[(a)]
            \item Replace $f$ by $\frac{f}{\| f \|_\infty}$ so we can assume that $\|f \|_\infty = 1$.  From the previous lemma, we know for each $n \geq 1$ there is a polynomial $p_n: [-1,1] \rightarrow \R$  such that $\left| |t| - p_n(t) \right| < \frac{1}{n}$ for all $t \in [-1,1]$. 
            
            Since $|f(x)| \leq \|f \|_\infty = 1$ for all $x \in X$, we have \[
                \left\| |f| - p_n(f) \right\| \leq \frac{1}{n}
            \] But $p_n(f)$ is a finite linear combination of $1, f, f^2, f^3, \dots$ and so in in $\mathcal{A}$, as $\mathcal{A}$ is unital.  Thus $|f| \in \overline{\mathcal{A}}$.  
            \item Use the formulas \[
                \max(f,g) = \frac{f+g - |f-g|}{2}, \quad \min(f,g) = \frac{f + g - |f-g|}{2} \in \overline{\mathcal{A}}
            \] and induction.  
        \end{enumerate}
    \end{proof}
    
    \begin{proof}[Proof of Stone-Weierstrass for $\mathcal{C}_\R(X)$]
        Let $f \in \mathcal{C}_\R(X)$ and let $\epsilon > 0$ be given.  We need to find $g \in \mathcal{A}$ such that \[
            |f(z) - g(z) | < \epsilon \quad \forall z \in X 
        \]
        
        \textbf{Step 0.}  We can assume that $\mathcal{A}$ is closed.  
        \begin{exer}
            Why?
        \end{exer} 
        
        \textbf{Step 1.}  Let $x,y \in X$ be fixed.  
        \begin{prop}
            There exists $f_{xy} \in \mathcal{A}$ with \[
                f_{xy}(x) = f(x), \quad f_{xy}(x) = f(y)
            \]
        \end{prop}
        \begin{proof}
            If $x = y$ then trivial (take $f_{xy}(z) = f(x) \mathbf{1}(z)$). 
            
            If $x \neq y$, since $A$ separates points, there is $h \in \mathcal{A}$ with $h(x) \neq h(y)$.  Then take \[
                f_{xy} = a h + b 1 \in \mathcal{A}
            \] we can invert the coefficient matrix to find our coefficients $a$ and $b$.  
        \end{proof}
        
        \textbf{Step 2.} Let $x \in X$ be fixed.  
        \begin{prop}
            There exists $f_x \in \mathcal{A}$ such that \begin{itemize}
                \item $f_x(x) = f(x)$.  
                \item $f_x(z) < f(z) + \epsilon$
            \end{itemize}
        \end{prop}
        \begin{proof}
            For each $y \in X$,let \[
                O_y = \{ z \in X \, | \, f_{xy}(z) < f(z) + \epsilon \}
            \] where $f_{xy}$ is the function from Step 1.  These are all open sets (why?) and thus \[
                X = \bigcup_{y \in X} O_y
            \] since $y \in O_y$.  
            
            By compactness of $X$, we have \[
                X = \bigcup_{i=1}^m O_{y_i}
            \]  Letting $f_x = \min(f_{xy_1}, \dots, f_{xy_n})$.  Then 
            \begin{itemize}
                \item Since $f_{xy_i}(x) = f(x)$ for all i, \[
                    f_x(x) = f(x)
                \]
                \item If $z \in X$, then $z \in O_{y_i}$ for some $i$, and so \[
                    f_x(z) \leq f_{x y_i}(z) < f(z) + \epsilon
                \] as required.
            \end{itemize} 
        \end{proof}
        
        \textbf{Step 3.}  \begin{prop}
            There exists a function $g \in \mathcal{A}$ such that \[
                |f(z) - g(z) | < \epsilon
            \] for all $z \in X$.  
        \end{prop}
        \begin{proof}
            For each $x \in X$, let \[
                U_x = \{ z \in X \, | \, f_x(z) > f(x) - \epsilon \} 
            \] where $f_x$ is from Step 2.  These sets $U_i$ are open and since $x \in U_x$, for an open cover, we can write \[
                X = \bigcup_{x \in X} U_x = \bigcup_{j=1}^n U_{x_j}.
            \]  
            Define $g = \max(f_{x_1}, \dots, f_{x_n})$.  If $z \in X$, 
            \begin{itemize}
                \item $g(z) = f_{x_i}(z)$ for some $i$, which is less than $f(z) + \epsilon$ from Step 2.
                \item If $z \in U_{x_j}$ for some $j = 1, \dots, n$, then \[
                    g(z) \geq f_{x_j}(z) > f(x) - \epsilon.  
                \]
            \end{itemize}
        \end{proof} 
    \end{proof}
    \begin{exer}
        Where did we use the Hausdorff property?
    \end{exer}
    
    We now prove for $\mathcal{C}_\Com(X)$.  
    
    Let \[ 
    \mathcal A_\R = \{ f \in \mathcal A \given \text{$f$ is real valued} \}. 
    \]  Then $\mathcal A_\R$ is an $\R$-subalgebra of $\mathcal C_\R(X)$.  It is unital, as $1 \in \mathcal A$ and it is real valued. 
    
    We now show $\mathcal A_\R$ separates points.  If $x \neq y$, there is $f \in \mathcal A$ such that $f(x) \neq f(y)$.  Write $f = u + iv$ with $u,v$ real valued.  Either $u(x) \neq u(y)$ or $v(x) \neq v(y)$, and so $\mathcal A_\R$ separates points.  
    
    Hence $\mathcal A_\R$ is dense in $\mathcal C_\R$.  
    
    Now, let $f \in \mathcal C_\Com(X)$.  Then write $f = u + iv$.  Then $u,v \in \mathcal C_\R(X)$.  Then given $\epsilon > 0$, there exists $u_1,v_1 \in \mathcal A_\R$ such that \[
        \| u - u_1 \|_\infty \leq \frac{\epsilon}{2}, \quad \| v - v_1 \|_\infty \leq \frac{\epsilon}{2} 
    \]  Writing $f_1 = u_1 + i v_1 \in \mathcal{A}$, we have \[
        \| f - f_1 \|_\infty \leq \| (u - u_1) + i(v-v_1) \|_\infty \leq \| u - u_1 \|_\infty + \| v - v_1 \|_\infty < \epsilon
    \] and thus $\mathcal{A}$ is dense in $\mathcal C_\Com(X)$.
\end{proof}


% section lecture_12_wednesday_6_april (end)

\section{Lecture 13 - Monday 11 April} % (fold)
\label{sec:lecture_13_monday_11_april}

\subsection{Applications of Stone-Weierstrass theorem} % (fold)
\label{sub:applications_of_stone_weierstrass_theorem}
\begin{cor}
    Polynomials are dense in $\mathcal C([a,b])$.  
\end{cor}
\begin{proof}
    $\mathcal A = \mathcal P([a,b])$ is an algebra, is unital, is closed under complex conjugation, and separates points.  Thus, $\mathcal A$ is dense in $\mathcal C([a,b])$.
\end{proof}

\begin{defn}[Trigonometric polynomials]
    A \textbf{trigonometric polynomail} is an expression \[
        \sum_{ n \in \Z} c_n e^{i n t}
    \] with finitely many $c_n \neq 0$. So these are polynomials in $s = e^{it}$ and $s^{-1} = \overline s = e^{-it}$.
\end{defn}

\begin{cor}
    The space $\mathcal A$ of all trigonometric polynomials is dense in $\mathcal C(\Pi)$, where $\Pi = \{ z \in \Com \, | \, |z | = 1 \}$
\end{cor}
\begin{proof}
    $\mathcal A$ is a sub-algebra of $\mathcal C(\Pi)$, it is unital, closed under complex conjugation, \[
        \overline{\sum_{n \in \Z} c_n e^{int}} = \sum_{n \in \Z} \overline{c_{-n}} e^{int}
    \] and separates points.  $T$ is a compact Hausdorff space, and thus Stone-Weierstrass states that $\mathcal{A}$ is dense in $\mathcal C(\Pi)$.  
\end{proof}

\begin{cor}
    The orthonomal system \[
        S = \{ \frac{1}{\sqrt{2\pi}} e^{int} \given n \in \Z \}
    \] is complete in $L^2([0, 2 \pi])$.  
\end{cor}
\begin{proof}
    $\spans{S} = \mathcal A$
 is a space of trigonometric polynomials, which is dense in $\mathcal C(\Pi)$.  Define \mapping{\Phi}{\mathcal C_p([0, 2 \pi])]}{\mathcal{C}(\Pi)}{f}{\tilde f}
where $\mathcal C_p([0, 2 \pi]) = \{ f \in \mathcal C([0, 2\pi] ) \given f(0 = f(2 \pi)) \}$.  Then $\Phi$ is an isometric isomorphism, and therefore functions of the form $f(t) = \sum c_n e^{i nt}$ is dense in $\mathcal C_p([0, 2\pi])$.  

By the construction of the Lebesgue integral, \textbf{simple} functions \[
    \sum_{i=1}^n a_i \mathbf{1}_{A_i}
\] are dense in $L^2([0, 2\pi])$.

\begin{exer}
    Given $f \in L^2([0, 2 \pi])$ and $\epsilon > 0$, there exists $g \in \mathcal C_p([0, 2\pi]) $ such that $\| f - g \|_2 < \epsilon$.  
\end{exer}

Thus $\mathcal A$ is dense in $L^2([0, 2 \pi])$.
\end{proof}

\begin{cor}
    The following are separable (have a countable dense subset):
    \begin{enumerate}[(a)]
        \item $ \mathcal C([a,b])$,
        \item $ L^p([a,b])$ , $ 1 \leq p < \infty$
    \end{enumerate}
\end{cor}
\begin{proof}
    \begin{enumerate}[(a)]
        \item We have $\mathcal P([a,b])$ is dense in $\mathcal C([a,b])$ and set $\mathcal P_\Q([a,b])$ with rational coefficients is dense in $\mathcal P([a,b])$.  Clearly, $\mathcal P_\Q([a,b])$ is countable, and thus is dense in $\mathcal{C}([a,b])$.
        \item Use the fact that $\mathcal C([a,b])$ is dense in $L^p([a,b])$.  
    \end{enumerate}
\end{proof}

\begin{cor}
    Let $X$ be a compact metric space.  Then $\mathcal C(X)$ is separable.
\end{cor}
\begin{proof}
    As $X$ is a compact metric space, then $X$ is separable.  
    \begin{exer}
        Why?
    \end{exer}
    Let $\{ x_n \given n \geq 1 \}$ be a countable dense subset of $X$.  For each $n \geq 1$ and $m \geq 1$ define \[
        f_{n,m} : X \rightarrow \K
    \] by \[f_{n,m}(x) = \inf_{z \notin B(x_n, \frac{1}{m})} d(x,z)\]
    We then claim $f_{n,m}$ is continuous.  Now, let $\mathcal{A}$ be the space of all $\K$-linear combinations of \begin{equation*}
        f^{k_1}_{n_1,m_1}, \dots, f_{n_l, m_l}^{k_l}, k_1, \dots, k_l \in \mathcal{N}. \tag{$\star$}
    \end{equation*}
 This is a sub-algebra of $\mathcal C(X)$, as $\mathcal A$ is unital, closed under conjugation, and separates points - if $z_1, z_2 \in X$ with $z_1 \neq z_2$, Choose $n,m$ such that $z_1 \in B(x_n, \frac{1}{m})$, $z_n \notin B(x_n, \frac{1}{m})$.  Thus the sub-algebra $\mathcal A$ is dense by Stone-Weierstrass.  
    
    The subset of $\Q$-linear combinations of $(\star)$ is countable and dense.
\end{proof}

\begin{lem}
    If $X$ is compact metric space then $X$ is separable.  
\end{lem}
\begin{proof}
    For each $m \geq 1$, \[
        X = \bigcup_{x \in X} B(x ; \frac{1}{m})
    \]  has a finite subcover \[
        X = \bigcup_{n=1}^{N_m} B(x_{m,n} \frac{1}{m})
    \] and thus the subset of all $\{x_{m,n} \}$ is a countably dense subset. 
\end{proof}

\begin{cor}
    \[
    \frac{pi^2}{6} = \sum_{n = 1}^\infty \frac{1}{n^2}.
    \] 
\end{cor}

\begin{proof}
    $S = \{ \frac{1}{\sqrt{2 \pi}} e^{i nt } \given n \in \Z \}$ is complete, and so Parseval's formula holds, \[
        \| f \|_2^2 = \sum_{ n \in \Z} | \iprod{f, e_n} |^2.
    \]  Apply to $f(x) = x$.  
\end{proof}

A common strategy is to prove for polynomials, and then Stone-Weierstrass proves it for continuous functions.  
\begin{cor}
    If $ f \in \mathcal C([a,b] \times [c,d])$ then \[
        \int_a^b \int_c^d f(x,y) \, dy dx = \int_c^d \int_a^b f(x,y) \, dx dy
    \]
\end{cor}

\begin{proof}
    By direct calculation, the result is true for two-variable polynomials.  Let $f \in \mathcal C([a,b] \times [c,d])$ and $\epsilon > 0$ be given.  By Stone-Weierstrass, the space of polynomials in 2 variables is dense in $\mathcal C([a,b] \times [c,d])$ and so there exists a polynomial $p(x,y)$ with \[
        |f(x,y) - p(x,y)| < \frac{\epsilon}{(b-a)(d-c)}.
    \]  The result then follows by direct calculation.
\end{proof}
% subsection applications_of_stone_weierstrass_theorem (end)
% section lecture_13_monday_11_april (end)

\section{Lecture 14 - Wednesday 13 April} % (fold)
\label{sec:lecture_14_wednesday_13_april}
The following is at the core of two of the cornerstone theorems of functional analysis - the uniform boundedness principle and the open mapping theorem.

\begin{thm}[Baire's theorem]
    Let $X$ be a complete metric space.  If $U_1, U_2, \dots$ are open dense subsets of $X$, then \[
        U = \bigcap_{n=1}^\infty U_n
    \] is dense in $X$.  
\end{thm}

\begin{proof}
    Let $x \in X$ and $\epsilon > 0$ be given.  We need to show that \[
        B(x, \epsilon) \cap U \neq \emptyset.
    \]
    
    \begin{lem}
        There exists sequences $(x_n)$ in $X$ and $(\epsilon_n)$ in $\R^+$ with the property that 
        \begin{enumerate}[(a)]
            \item $x_1 = x$, $\epsilon_1 = \epsilon$.  
            \item $\epsilon_n \downarrow 0$
            \item $\overline{ B(x_{n+1}, \epsilon_{n+1})} \subseteq B(x_n, \epsilon_n) \cap U_n$ for all $n \geq 1$.  
        \end{enumerate} 
    \end{lem}
    \begin{proof}
        Let $x_1, \dots, x_n$ and $\epsilon_1, \dots, \epsilon_n$ be chosen.  By density of $U_n$, \[
            B(x_n, \epsilon_n) \cap U_n \neq \emptyset.
        \]
        Choose $x_{n+1} \in B(x_n, \epsilon_n) \cap U_n$.  Choose $\epsilon'_{n+1} > 0$ such that $B(x_{n+1}, \epsilon'_{n+1}) \subseteq B(x_n, \epsilon_n) \cap U_n$ (openness).  We have $\epsilon_{n+1}' \leq \epsilon_n$.  Choose $0 \leq \epsilon_{n+1} \leq \min(\frac{\epsilon'_{n+1}}{2}, \frac{1}{n+1})$, then we have \begin{align*}
            \overline B(x_{n+1}, \epsilon_{n+1}) &\subseteq B(x_{n+1}, \epsilon'_{n+1}) \\
            &\subseteq B(x_n, \epsilon_n) \cap U_n
        \end{align*}
        and $\epsilon_{n+1} < \epsilon_n$ with $\epsilon_{n+1} < \frac{1}{n+1}$.
    \end{proof}
    
    Given the lemma, the theorem follows.  If $m \geq n$, then by (c), \[
        B_(x_m, \epsilon_m) \subseteq B(x_n, \epsilon_n) \cap U_n \tag{$\star$} 
        \]
    In particular, $x_m \in B(x_n, \epsilon_n)$.  Thus, $d(x_n, x_m) < \epsilon_n$ for all $m \geq n$.  Thus $(x_n)$ is Cauchy, and so $x_n \rightarrow \zeta$ in $X$ by completeness.  By $(\star)$, we then have $d(x_n, \zeta) \leq \epsilon_n$ for all $n \geq 1$.  So $\zeta \in \overline{B(x_n, \epsilon_n)}$.  So by (c), $\zeta \in \overline{B(x_{n+1}, \epsilon_{n+1})} \subseteq B(x_n, \epsilon_n) \cap U_n$.
    
    Thus $\zeta \in B(x, \epsilon)$ and thus $\zeta \in U = \bigcap_{n=1}^\infty U_n$.          
\end{proof}

The following corollary is often used
\begin{cor}
    Let $X$ be a complete metric space. If $C_1, C_2, \dots$ are closed with $X = \bigcup_{n=1}^\infty$ then $\text{Int} (C_n) \neq \emptyset$ for some $n$.
\end{cor}
\begin{proof}
    If $\text{Int}(C_n) = \emptyset$ for all $n$ then $U_n = X \backslash C_n$ are open and dense.  So by Baire's theorem, $\cap_{n=1}^\infty U_n$ is sense, and in particular, $\bigcap{n=1}^\infty U_n \neq \emptyset$. We have 
    \begin{align*}
        X  = \bigcup_{n=1}^\infty C_n &= \bigcup_{n=1}^\infty (X \backslash U_n) \\
        &= X \backslash (\bigcap_{n=1}^\infty U_n) \\
        &\subsetneq X,
    \end{align*} a contradiction.
\end{proof}

There are three cornerstone theorems. 

\begin{itemize}
    \item Hahn-Banach,
    \item Uniform Boundedness,
    \item Open Mapping.
\end{itemize}

\begin{thm}[Uniform boundedness]
    Let $X, Y$ be Banach spaces.  Let $T_\alpha$, $\alpha \in A$, a family of continuous linear operators $T_\alpha : X \rightarrow Y$.  Then if \[
        \sup_{\alpha \in A} \| T_\alpha x \| < \infty
    \] for each fixed $x \in X$, then \[
        \sup_{\alpha \in A} \| T_\alpha \| < \infty
    \]
\end{thm}
\begin{rem}
    Rather amazing - you get a global bound from pointwise bounds.
\end{rem}
\begin{proof}
    For each $n \geq 1$, let \[
        X_n = \{ x \in X \given \| T_\alpha x \| \leq n \, \forall \alpha \in A \}
    \]  These are \textbf{closed} ($T_{\alpha}$ is continuous) and \[
        X = \bigcup_{n=1}^\infty X_n
    \] by the hypothesis.
    
    By the corollary to Baire's theorem, we know there exists $n_0 \geq 1$ with $\text{Int}(X_{n_0}) \neq \emptyset$.  Choose $x_0 \in \text{Int}(X_{n_0})$, and let $r > 0$ such that \[
        B(x_0, r) \subseteq \text{Int}(X_{n_0}).  
    \]  
    
    If $\| z \| \leq 1$ then $x_0 + rz \in \overline B (x_0, r)$. So $x_0 + rz \in X_{n_0}$, and \[
        \| T_\alpha(x_0 + rz) \| \leq n_0 \, \forall \alpha \in A,
    \]  but $| \| a \| - \| b \| | \leq \| a + b \|$, so \[
        \| T_\alpha (rz) \| - \| T_\alpha (x_0) \| \leq \| T_\alpha (x_0 + rz) \| \leq n_0.
    \]
    So $r \| T_\alpha z \| \ \leq n_0 + n_0$, and \[
        \| T_\alpha z \| \leq \frac{2 n_0}{r} \, \forall \| z \| \leq 1, \forall \alpha \in A
    \]
    
    For a general $x \in X$, \[
        \| T_\alpha x \| = \| T_\alpha ( \frac{x}{\| x \|}) \| x \| \leq \frac{2 n_0}{r} \| x \|
    \] and thus $\|T_\alpha \| \leq \frac{2 n_0}{r}$, which implies \[
        \sup_{\alpha \in A} \| T_\alpha \| < \infty \qedhere
    \]
    
    
\end{proof}
% section lecture_14_wednesday_13_april (end)

\section{Lecture 15 - Monday 18 April} % (fold)
\label{sec:lecture_15_monday_18_april}
Recall, the Fourier series of $f \in L^2([-\pi, \pi])$ is \[
    \sum_{k \in \Z} \iprod{f, e_k} e_k
\] where $e_k(t) = \frac{e^{ikt}}{\sqrt{2 \pi}}$.  This converges to $f$ in the $L^2$ norm.

\begin{exer}
    If $f$ is $2\pi$-periodic and continuous, does the Fourier series converge pointwise?  
\end{exer}

There are explicit (complicated) examples, but the easiest existence is using the uniform boundedness principle.  

\begin{prop}
    There is a $2\pi$ periodic continuous function whose Fourier series does not converge at 0.  
\end{prop}
\begin{proof}
    Let $\mathcal{C}_p([-\pi, \pi]) = \{ f \in \mathcal C([-\pi, \pi]) \given f(-\pi) = f(\pi) \}.$  This is a Banach space with $\| \cdot \|_\infty $.  If $f \in \mathcal C_p$, let \[
        f_n = \sum_{|k | \leq n} \iprod{f, e_k} e_k.
    \]
    
\begin{rem}
    We can now define, for each $n \geq 1$, a linear operator $T_n : \mathcal C_p \rightarrow \K$ by \[
        T_n(f) = f_n(0). 
    \]  If $f_n(0)$ converges (as $ n \rightarrow \infty$) for each $f \in \mathcal C_p$, then \[
        \sup_{n \geq 1} |T_n f | = \sup_{n \geq 1} |f_n(0)| < \infty
    \] for all $f \in \mathcal C_p$, which by uniform boundedness implies \[
        \sup_{n \geq 1} \| T_n \| \leq \infty \tag{$\star$}.
    \]  
    We now show that $(\star)$ is false.
\end{rem}
We have \begin{align*}
    f_n(x)  &= \sum_{| k \leq n} \frac{1}{2 \pi} \int_{-\pi}^\pi f(t) e^{-ikt} \, dt e^{ikx}  \\
            &= \frac{1}{2\pi} \int_{-\pi}^\pi f(t) \left( \sum_{|k| \leq n} e^{-ik(x-t)} \right) \, dt \\
            &= \frac{1}{2 \pi} \int_{-\pi}^\pi f(t) D_n(x-t) \, dt 
\end{align*} where $D_n(t) = \sum_{|k| \leq n} e^{ikt}$ is the \textbf{Dirichlet Kernel}.  The Dirichlet kernel is real, and even, with \[
    D_n(t) = \frac{\sin(n+\frac{1}{2}) t}{\sin \frac{t}{2}}.  
\]  

\begin{note}
    $T_n$ is continuous, with norm $\| T_n \| = \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t) | \, dt$.
\end{note}
\begin{proof}
    \begin{align*}
        |T_n(f)| &\leq \frac{1}{2\pi} \int_{-\pi}^\pi |f(t)| |D_n(t)| \, dt \\
                &\leq \left( \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t)| \, dt \right) \| f\|_\infty
    \end{align*} and so $\|T_n \| \leq \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t)| \, dt$. 
    
    Going the other way, let \[
        s_t = \begin{cases}
        1 &D_n(t) \geq 0 \\
        -1 &D_n(t) < 0
        \end{cases}.
    \]  We have seen hat set functions can be approximated in $L^1$-norm by continuous (periodic) functions.  So if $\epsilon > 0$ is given, there is a $g \in \mathcal C_p$ such that \[
        \left| \frac{1}{2\pi} \int_{-\pi}^\pi (g(t) - s(t))D_n(t) \, dt \right| < \epsilon. 
    \] $g$ can be chosen with $\| g \|_\infty = 1$.  
    
      So \[
        \left| T_n(g) - \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t)| \, dt \right| < \epsilon.
    \]  Thus \[
        \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t) | \, dt - |T_n(g)| < \epsilon.  
    \]  So \[
        |T_n(g)| \geq \frac{\| g \|_\infty}{2 \pi} \int_{-\pi}^\pi |D_n(t)| \, dt - \epsilon. 
    \]  Since $\epsilon > 0$ was arbitrary, \[
        \|T_n \| \geq \frac{1}{2 \pi} \int_{-\pi}^\pi |D_n(t) | \, dt. \qedhere
    \]
\end{proof}

All that remains is to show that \[
    \|T_n \| = \frac{1}{2\pi} \int_{-\pi}^\pi |D_n(t)| \, dt \rightarrow \infty
\]  We have 
\begin{align*}
    \|T_n \|    &= \frac{1}{\pi}\int_0^\pi |D_n(t) | \, dt \\
                &= \frac{1}{\pi} \int_0^\pi \frac{|\sin(n+\frac{1}{2})t|}{|\sin \frac{t}{2}|} \, dt \\
                &\geq \frac{2}{\pi} \int_0^\pi \frac{|\sin(n+\frac{1}{2}) t |}{t} \, dt \\
                &= \frac{2}{\pi} \int_0^{(n+\frac{1}{2})\pi} \frac{\sin v}{v} \, dv \\
                &\geq \frac{2}{\pi} \int_0^{n\pi} \frac{\sin v}{v} \, dv \\
                &= \frac{2}{\pi} \sum_{k=1}^n \int_{(k-1)\pi}^{k \pi} \frac{|\sin v|}{v} \, dv \\
                &\geq \sum_{k=1}^n \frac{1}{k \pi} \int_{(k-1)\pi}^{k \pi} |\sin v | \, dv \\
                &= \frac{4}{\pi^2} \sum_{k =1 }^n \frac{1}{k} \rightarrow \infty
\end{align*} as $n \rightarrow \infty$.  

Thus there exists $f \in \mathcal C_p$ such that the Fourier series of $f$ diverges at $x = 0$.  
\end{proof}

\subsection{The open mapping theorem} % (fold)
\label{sub:the_open_mapping_theorem}
This theorem is \emph{tailor-made} to deal with inverse operators.

\begin{defn}[Open mapping]
    Let $X, Y$ be metric spaces.  A function $f : X \rightarrow Y$ is \textbf{open} if open sets in $X$ are mapped to open sets in $Y$.  
\end{defn}

\begin{thm}[Open mapping theorem]
    Let $X, Y$ be Banach spaces.  If $T \in \mathcal{L}(X,Y)$ is surjective then $T$ is open. 
\end{thm}

\begin{cor}[Bounded inverse theorem]
    Let $X, Y$ be Banach spaces.  If $T \in \mathcal L(X,Y)$ is bijective, then \[
        T^{-1} \in \mathcal L(Y,X).
    \]
    
\end{cor}
\begin{proof}
    Let $O \subseteq X$ be open.  Then $(T^{-1})^{-1}(O) = T(O)$ is open (by the open mapping theorem).  Thus $T^{-1}$ is continuous.
\end{proof}

\begin{cor}
    Let $(X, \| \cdot \|_1)$ and $(X, \| \cdot \|_2)$ be Banach spaces.  If \[
        \| x \|_1 \leq C \| x \|_2 \quad \forall x \in X
    \] then $\| \cdot \|_1$ and $\| \cdot \|_2$ are equivalent.  
\end{cor}
\begin{proof}
    \mapping{i}{(X, \| \cdot \|_2)}{(X, \| \cdot \|_1)}{ x}{x} is linear, surjective and injective, and also continuous, as \[
        \|i(x) \| = \| x \|_1 \leq C \| x \|_2.
    \]  So the bounded inverse theorem gives \[
        i^{-1} : (X, \| \cdot \|_1) \rightarrow (X, \| \cdot \|_2)
    \] is continuous.  Thus there exists $A > 0$ such that $\| i^{-1}(x)\|_2 \leq A \| x \|_1$, which implies $\| x \|_2 \leq A \| x \|_1$.  So \[
        \frac{1}{A} \| x \|_2 \leq \| x \|_1 \quad \forall x \in X \qedhere
    \]  More generally, if $T \in \mathcal L(X,Y)$ is bijective, then by the bounded inverse theorem, \[
        c \| x \| \leq \| Tx \| \leq C \| x \|
    \] where $c  = \frac{1}{ \| T^{-1} \|}$, $C = \| T \|$.  
\end{proof} 
% subsection the_open_mapping_theorem (end)
% section lecture_15_monday_18_april (end)

\section{Lecture 16 - Wednesday 20 April} % (fold)
\label{sec:lecture_16_wednesday_20_april}


\begin{lem}
    Let $X$ be a Banach space and $Y$ a normed space.  Then for $T \in \mathcal L(X, Y)$, the following are equivalent.
    \begin{enumerate}[(a)]
        \item $T$ is open
        \item There exists $r > 0$ such that $B(0, r) \subseteq T(\overline{B(0, 1)})$
        \item There exists $r > 0$ such that $B(0, r) \subseteq \overline{T(\overline{B(0, 1)})}$.
    \end{enumerate} 
\end{lem}

\begin{proof}
    $(a) \Rightarrow (b), (c)$.  As $B(0, 1)$ is open, the set $T(B(0,1))$ is open in $Y$.  Since $0 \in T(B(0,1))$ there exists $ > 0$ such that the set 
    \[
    B(0, r) \subseteq T(B(0,1)) \subseteq T(\overline{B(0,1)}) \subseteq \overline{T(\overline{B(0,1)})}.
    \] 
    
    $(c) \Rightarrow (b)$.  Assume that there exists $r > 0$ such that \[
        B(0 ,r) \subseteq \overline{T(\overline{B(0,1)})}.
    \] We now show that $B(0, \frac{r}{2}) \subseteq T(\overline{B(0,1)})$ which proves $(b)$.  Let $y \in B(0, \frac{r}{2})$.  Then $2y \in B(0, r)$ and since $B(0, r) \subseteq \overline{T(\overline{B(0,1)})}$ there exists $x_1 \in \overline{B(0,1)}$ such that \[
        \| 2y - Tx_1 \| \leq \frac{r}{2}
    \]  Hence $4y - 2Tx_1 \in B(0, r) $ and by the same argument as before there exists $x_2 \in \overline{B(0,1)}$ such that \[
        \| 4y  - 2Tx_1 - Tx_2 \| \leq \frac{r}{2}
    \] Continuing this way we construct a sequence $(x_n) \in \overline{B(0, 1)}$ such that \[
        \| 2^n y - 2^{n-1} T x_1 - \dots - 2T x_{n-1} - T x_n\| \leq \frac{r}{2}
    \]  for all $n$.  Dividing by $2^{n}$ we obtain \[
        \| y - \sum_{k=1}^n 2^{-k} T x_k \| \leq \frac{r}{2^{n+1}}
    \]  Hence $y = \sum_{k=1}^\infty 2^{-k} T x_k$. 
    Since $\| x_k \| \leq 1$ for all $ k \in \N$ we have that \[
        \sum_{k=1}^\infty 2^{-k} \| x_k \| \leq \sum_{k=1}^\infty 2^{-k} = 1
    \] and so the series \[
        x = \sum_{k=1}^\infty 2^{-k} x_k
    \] converges absolutely in $X$ as $X$ is Banach and hence complete.  We have also that $\| x \| \leq 1$ and so $x \in \overline{B(0,1)}$.  Because $T$ is continuous we have \[
        Tx = \lim_{n \rightarrow \infty} \sum_{k=1}^n 2^{-k} T x_k = y
    \] by construction of $x$.  Hence $y \in T(\overline{B(0,1)})$ and $(b)$ follows.

    $(b) \Rightarrow (a)$.  By $(b)$ and the linearity of $T$ we have \[
        T(\overline{B(0, \epsilon)}) = \epsilon T(\overline{B(0, 1)})
    \] for all $\epsilon > 0$.  Since the map $x \mapsto \epsilon x$ is a homeomorphism on $Y$ the set $T(\overline{B(0, \epsilon)})$ is a neighbourhood of zero for all $\epsilon > 0$.  Now let $U \subseteq X$ be open and $y \in T(U)$.  As $U$ is open there exists $\epsilon > 0$ such that \[
        \overline{B(x, \epsilon)} = x + \overline{B(0, \epsilon)} \subseteq U
    \] where $y = Tx$.  Since $z \mapsto x + z$ is a homeomorphism and $T$ is linear we have \[
        T(\overline{B(x, \epsilon)}) = Tx + T(\overline{B(0, \epsilon)}) = y + T(\overline{B(0, \epsilon)}) \subseteq T(U).
    \]  Hence $T(\overline{B(x, \epsilon)})$ is a neighbourhood of $y$ in $T(U)$.  As $y$ was arbitrary in $T(U)$ it follows that $T(U)$ is open.  
\end{proof} 

\begin{lem}
    Let $X$ be a normed vector space and $S \subseteq X$ convex with $S = -S$. If $\overline{S}$ has a non-empty interior, then $\overline{S}$ is a neighbourhood of zero.
\end{lem}

\begin{proof}
    First note that $\overline{S}$ is convex.  If $x, y \in S$ and $x_n, y_n \in S$ with $x_n, y_n \rightarrow x, y$ then $tx_n + (1-t y_n) \in S$ for all $n$ and $t \in [0,1]$.  Letting $n \rightarrow \infty$ we get $tx + (1-t) y \in \overline S$ for all $t \in [0,1]$ and so $\overline S$ is convex.  We also easily have $\overline S = - \overline S$.  If $\overline S$ has a non-empty interior, there exists $z \in \overline S$ and $\epsilon > 0$ such that $B(z, \epsilon) \subseteq \overline S$.  Therefore $z \pm h \in \overline S$ whenever $\| h \| < \epsilon$ and since $\overline S = - \overline S$ we also have $-(z \pm h) \in \overline S$. By the convexity of $\overline S$ we have \[
        y = \frac{1}{2}( (x + h) + (-x + h)) \in \overline S
    \] whenever $\| h \| < \epsilon$.  Hence $B(0, \epsilon) \subseteq \overline S$, and so $\overline S$ is a neighbourhood of zero.
\end{proof}

\begin{thm}[Open mapping theorem]
    Suppose that $X$ and $Y$ are Banach spaces.  If $T \in \mathcal L(X, Y)$ is surjective, then $T$ is open.
\end{thm}
\begin{proof}
    As $T$ is surjective we have \[
        Y = \bigcup_{n \in \N} \overline{T(\overline{B(0, n)})} 
    \] with $\overline[T(\overline{B(0, n)})]$ closed for all $n \in \N$.  Since $Y$ is complete, by a corollary to Baire's theorem, there exists $n \in \N$ such that $\overline{T(\overline{B(0, n)})}$ has non-empty interior. Since the map $x \mapsto nx$ is a homeomorphism and $T$ is linear, the set $\overline{T(\overline{B(0, 1)})}$ has non-empty interior as well.  Now $\overline{B(0, 1)}$ is convex and $\overline{B(0, 1)} = - \overline{B(0, 1)}$.  By linearity of $T$ we have that \[
        T(\overline{B(0, 1)}) = - T(\overline{B(0, 1)})
    \] is convex as well.  Since we know that $\overline{T(\overline{B(0, 1)})}$ has non-empty interior, the previous lemma implies that $\overline{T(\overline{B(0, 1)})}$ is a neighbourhood of zero, and thus there exists $r > 0$ such that \[
        B(0, r) \subseteq \overline{T(\overline{B(0, 1)})}
    \] and since $X$ is Banach the previous lemma shows that $T$ is open.
\end{proof}
% section lecture_16_wednesday_20_april (end)

\section{Lecture 17 - Monday 1 May} % (fold)
\label{sec:lecture_17_monday_1_may}

\begin{exer}
    If $X, Y$ are vector spaces, and if $T: X \rightarrow Y$ is linear, then $\Gamma(T)$ is a subspace of $X \times Y$.  Moreover, if $X, Y$ are normed vectors paces, with \[
        \| (x, Tx) \|_\Gamma = \| x \| + \| Tx \|.
    \]  
\end{exer}

\begin{thm}[Closed Graph theorem]
    Let $X, Y$ be Banach spaces, and $T \in \text{Hom}(X,Y)$.  Then $T \in \mathcal L(X,Y)$ if and only if $\Gamma(T)$ is closed in $X \times Y$.  
\end{thm}

\begin{proof}
    Suppose $T \in \mathcal L(X,Y)$.  If $x_n \rightarrow x$ in $X$, then \[
        (x_n, Tx_n) \rightarrow (x, Tx)
    \] by continuity of $T$, and so $\Gamma(T)$ is closed.
    
    Conversely, suppose that $\Gamma(T)$ is closed in $X \times Y$.  Define a norm $\| \cdot \|_\Gamma$ on $X$ by $\| x \|_\Gamma = \| x \| + \| Tx \|$.  Since $\Gamma(T)$ is closed, and since $(X, \| \cdot \|)$ is Banach, then $(X, \| \cdot \|_\Gamma)$ is also a Banach space (exercise).  Note that $\| x \| \leq \| x \|_\Gamma$.  So by a corollary to the Open Mapping theorem, $\| \cdot \|$ and $\| \cdot \|_\Gamma$ are equivalent.  So there is $c > 0$ with \[
        \| x \|_\Gamma \leq c \| x \| \quad \forall x \in X.
    \]    So $\| x \| + \| Tx \| \leq c \| x \|$, and so $\| Tx \| \leq (c-1) \| x \|$, and so $T$ is continuous.
\end{proof}

\subsection{Spectral Theory} % (fold)
\label{sub:spectral_theory}
The eigenvalues of an $n \times n$ matrix $T$ over $\Com$ are the $\lambda \in \Com$ with \[
    \det(\lambda I - T) = 0
\] that is, $\lambda I - T$ is not invertible.

\begin{rem}
    Showing existence of eigenvalues is equivalent to the fundamental theorem of algebra.  
\end{rem}
\begin{rem}
    We need our base field to be $\Com$ to get reasonable spectral theory.
\end{rem}

\begin{defn}
Write $\mathcal L(X) = \mathcal L(X,X)$. 
\end{defn}

\begin{defn}
    Let $X$ be a Banach space over $\K$, and let $T \in \mathcal L(X)$.  Then the spectrum of $T$ is \[
        \sigma(T) = \{ \lambda \in \K \given \text{$\lambda I - T$ is not invertible} \}.
    \]
\end{defn}  
\begin{rem}
    $\lambda I - T$ is non invertible if either $\lambda I - T$ is not injective, or $\lambda I - T$ is not surjective.  
\end{rem}
\begin{rem}
    If $\dim(X) < \infty$, then $X \backslash \ker(T) \simeq \text{im}(T)$, and so $T$ is injective if and only if $T$ is surjective. This fails in the infinite dimensional case - consider the left and right shift operators on $\ell^2$.   
\end{rem}

\begin{defn}[Eigenvalue]
$\lambda \in \K$ is an eigenvalue of $T \in \mathcal L(X)$ if there is $ x \neq 0$ with $Tx = \lambda x$, i.e. $\lambda$ is an eigenvalue if and only if $\lambda I - T$ is not injective.
\end{defn}

\begin{thm}
    Let $X \neq \{ 0 \}$ be a Banach space over $\Com$, and let $T \in \mathcal L(X)$.  Then $\sigma(T)$ is a non-empty, compact (closed and bounded) subset of \[
        \{ \lambda \in \Com \given | \lambda | \leq \| T \| \}
    \]
\end{thm}

\begin{exmp}
    Let $L, R : \ell^2 \rightarrow \ell^2$ be the left and right shift operators.  
    
    Then $\| L \| = 1$, and so $\sigma(L) \subseteq \overline D(0,1)$.  If $| \lambda | < 1$, then \[
        L(\lambda, \lambda^2, \lambda^3, \dots) = (\lambda^2, \lambda^3, \lambda^4, \dots) = \lambda(\lambda, \lambda^2, \lambda^3,\dots)
    \] 
    and so $\lambda$ is an eigenvalue.  Thus $D(0,1) \subseteq \sigma(L) \subseteq \overline D(0,1)$.  But $\sigma(L)$ is closed, and so $\sigma(L) = \overline D(0,1)$.  Are the $\lambda$ with $| \lambda | = 1$ eigenvalues?  No - suppose $| \lambda | = 1$ and $x \neq 0$ with $Lx = \lambda x$.  
    
    Then \[
        L^n (x) = \lambda^n x.  
    \]  Thus, $x_{n+1} = \lambda^n x_1$.  Then $x = (x_1, \lambda, x_1, \lambda^2 x_1, \dots)$ which is not in $\ell^2$.
    
    Then $\| R \| = 1$, and so $\sigma(R) \subseteq \overline D(0,1)$.
    
    \begin{note}
        $LRx = L(0, x_1, \dots) = (x_1, x_2, \dots)$, so \[
            LR = I \tag{$\star$}
        \]
    \end{note}
    \begin{rem}
        Unlike $\dim(X) < \infty$, $(\star)$ does NOT say that $R$ is invertible $(RL = I)$.
    \end{rem}

    Consider the operator $L(\lambda I - R) = \lambda L - I = -\lambda(\lambda^{-1} I - L)$.  If $0 < | \lambda | < 1$, then we know that $\lambda^{-1}I - L$ is invertible (as $\lambda^{-1} \notin \sigma(L)$).  So if $\lambda I - R$ were invertible, then $L$ is invertible, which is false. Thus $\lambda \in \sigma(R)$. Hence \[
        D(0,1) \backslash \{ 0 \} \subseteq \sigma(R) \subseteq \overline D(0,1).  
    \]  Since $\sigma(R)$ is closed, $\sigma(R) = \overline D(0,1)$. 
\end{exmp} 
% subsection spectral_theory (end)
% section lecture_17_monday_1_may (end)

\section{Lecture 18 - Wednesday 4 May} % (fold)
\label{sec:lecture_18_wednesday_4_may}
\begin{thm}
    Let $X \neq \{ 0 \}$ be a Banach space over $\Com$.  Let $T \in \mathcal L(X)$.  Then $\sigma(T)$ is a nonempty, compact subset of \[
        \{ \lambda \in \Com \given | \lambda | \leq \| T \| \}.
    \]
\end{thm}

\begin{lem}
    With above assumptions $\sigma(T) \subseteq \{ \lambda \in \Com \given | \lambda | \leq \| T \| \}$.  
\end{lem}

\begin{proof}
    We need to show that if $|\lambda | > \| T \|$ then $\lambda I - T$ is invertible.  
    
    \textbf{Technique: Geometric series}.  We guess \[
        (\lambda I - T)^{-1} = \frac{1}{\lambda I - T} = \sum_{k = 0}^\infty \frac{T^k}{\lambda^{k+1}}.
    \]  We now verify this guess.  Since $$\sum_{k=0}^{\infty} \frac{\| T^k \|}{|\lambda|^{k+1}} \leq \sum_{k=0}^\infty \frac{\| T \|^k}{|\lambda|^{k+1}} < \infty,$$ the series $S = \sum_{k=0}^\infty \frac{T^k}{\lambda^{k+1}}$ converges in X.  
    
    We now show that $S$ is the inverse of $\lambda I - T$.  As we are working in infinite dimensions, we ned to check left and right inverses. Let $S_n = \sum_{k=1}^{n-1} \frac{T^k}{\lambda^{k+1}}$. Then 
    \begin{align*}
        S_n (\lambda I - T) &= \left( \sum_{k=0}^{n-1} \frac{T^k}{\lambda^{k+1}} \right) \left( \lambda I - T \right) \\
        &= I - \frac{T^n}{\lambda^n} \rightarrow I \\
        (\lambda I - T) S_n &= I - \frac{T^n}{\lambda^n} \rightarrow I
    \end{align*} and so $S(\lambda I - T) = (\lambda I - T) S$ and so $\lambda I - T$ is invertible.  
\end{proof}

\begin{exer}
    Show that if $\| I - T \| < 1$ then $T$ is invertible with inverse $\sum_{k=0}^\infty (I-T)^k$ \emph{Hint: Consider \[
        \frac{1}{T} = \frac{1}{I - (I-T)}.
    \]}
    In particular, the ball $B(I, 1)$ in $\mathcal L(X)$ consists of invertible elements.  
\end{exer}

The following is used to show $\sigma(T)$ is closed and nonempty, it is also interesting in its own right.  \begin{prop}
    Let $X$ be Banach over $\K$.  Let $\text{GL}(X) = \{ T \in \mathcal L(X) \given \text{$T$ invertible}$.  Then \begin{enumerate}[(a)]
        \item $\text{GL}(X)$ is a group under composition of operators.
        \item $\text{GL}(X)$ is open in $\mathcal L(X)$.  
        \item The map \mapping{\phi}{\text{GL}(X)}{\text{GL}(X)}{T}{T^{-1}} is continuous.
    \end{enumerate}
\end{prop}

\begin{proof}
    \begin{enumerate}[(a)]
        \item The open mapping theorem tells us that if $T \in \text{GL}(X)$ then $T^{-1} \in \mathcal L(X)$, and so $T^{-1} \in \text{GL}(X)$.  The rest is clear.
        \item Let $T_0 \in \text{GL}(X)$.  We claim \[
            B\left(T_0, \frac{1}{\| T_0^{-1}} \|\right) \subseteq \text{GL(X)}.
        \]  We have \begin{align*}
            \| I - T_0^{-1} T \|    &= \| T_0^{-1}(T_0 - T) \| \\ 
                                    &\leq \| T_0^{-1} \| \| T_0 - T \| \\
                                    &< 1 \quad \text{as $T \in B\left(T_0, \frac{1}{\| T_0^{-1} \|}\right) $}
        \end{align*}
        \item We have \begin{align*}
            \| T_0^{-1} - T^{-1} \| &= \| T^{-1} ( T - T_0) T_0^{-1} \ | \\
                                    &\leq \| T^{-1} \| T - T_0 \| \| T_0^{-1} \| \tag{$\star$}
        \end{align*}  If $\| T - T_0 \| \leq \frac{1}{2 \| T_0^{-1} \|}$, then 
        \begin{align*}
            \| I - T T_0^{-1} \| &= \| (T_0 - T) T_0^{-1} \| \\
                                &\leq \| T_0 - T \| \| T_0^{-1} \| \\
                                &\leq \frac{1}{2}.
        \end{align*}  We then have 
        \begin{align*}
            \| T_0 T^{-1} \|    &= \| (T T_0^{-1})^{-1} \| \\
                                &= \| \sum_{k=0}^\infty ( I - T T_0^{-1})^k \| \\
                                &\leq \sum_{k=0}^\infty \| I - T T_0^{-1} \|^k \\
                                &\leq 2
        \end{align*} 
        
        Hence $\|T^{-1}\| = \|T_0^{-1}( T_0 T^{-1}) \| \leq \| T_0^{-1} \| \| T_0 T^{-1} \| \leq 2 \| T_0^{-1} \|$, and from $(\star)$, we have \[
            \| T_0^{-1} - T^{-1} \| \leq 2 \| T_0^{-1} \|^2 \| T - T_0 \|
        \] and so $T \mapsto T^{-1}$ is continuous.  
    \end{enumerate}
\end{proof}

\begin{cor}
    $\sigma(T)$ is closed.
\end{cor}

\begin{proof}
    Let \mapping{f}{\Com}{\mathcal L(X)}{\lambda}{\lambda I - T}  This is continuous, as \begin{align*}
        \| f(\lambda) - f(\lambda_0) \| &= \| (\lambda - \lambda_0) I \| \\
                                        &= | \lambda - \lambda_0 |
    \end{align*} and \begin{align*}
            \sigma(T) = f^{-1}\left(\mathcal L(X) \backslash \text{GL}(X) \right)
    \end{align*} which is the inverse image of a closed set, and hence is closed.
\end{proof}

So $\sigma(T)$ is a compact subset of $\{ \lambda \in \Com \given | \lambda | \leq \| T \| \}$.  Write $\rho(T) = \Com \backslash \sigma(T)$ (the \textbf{resolvent set}), and let $R_T = R : \rho(T) \rightarrow \mathcal L (X)$ with $R_T(\lambda) = (\lambda I - T)^{-1}$.

\begin{thm}
    Let $\K = \Com$ and $X \neq \{ 0 \}$ and $T \in \mathcal L(X)$.  Then $\sigma(T) \neq \emptyset$.
\end{thm}

\begin{proof}
    We use Lioville's theorem - a bounded entire function must be constant.  
    
    Let $\phi = \mathcal L(X)'$ (hence $\phi : \mathcal L(X) \rightarrow C$.)  Let \mapping{f_\phi}{\rho(T)}{\Com}{\lambda}{\phi(R(\lambda))} 
    \begin{lem}
     $f_\phi$ is analytic on $\rho(T)$.         
    \end{lem}
    \begin{proof}
        We show $f_\phi$ is differentiable.  Consider \begin{align*}
            \frac{f_\phi(\lambda) - f_\phi(\lambda_0)}{\lambda - \lambda_0} &= \phi\left(\frac{R(\lambda) - R(\lambda_0)}{\lambda - \lambda_0} \right)  \\
            &= \phi \left( \frac{(\lambda I - T)^{-1} - (\lambda_0 I - T)^{-1}}{\lambda - \lambda_0}  \right) \\
            &= \phi \left( \frac{(\lambda_0 I - T)^{-1}( (\lambda_0 - \lambda) I)(\lambda I - T)^{-1}}{\lambda - \lambda_0} \right) \\
            &= -\phi \left( (\lambda_0 I - T)^{-1} (\lambda I - T)^{-1} \right) \\
            &\rightarrow -\phi \left( (\lambda_0 I - T)^{-2} \right)
        \end{align*} 
        as $\lambda \rightarrow \lambda_0$, where we use the fact that $\phi$ is continuous and $T \rightarrow T^{-1}$ is continuous.    So $f_\phi$ is analytic on $\rho(T)$ for all $\phi \in \mathcal L(X)'$.  
    \end{proof}
    
    Now suppose that $\sigma(T) = \emptyset$.  Then $f_\phi : \Com \rightarrow \Com$ is analytic.
    
    \begin{lem}
        $f_\phi$ is bounded.  
    \end{lem}
    \begin{proof}
        If $|\lambda > \| T \|$, then \begin{align*}
            f_\phi(\lambda) &= \left| \phi \left( ( \lambda I - T)^{-1} \right) \right| \\
                            &= \left| \phi \left( \sum_{k=0}^\infty \frac{T^k}{\lambda^{k+1}} \right) \right| \\
                            &\leq \| \phi \| \left \| \sum_{k=0}^\infty \frac{T^k}{\lambda^{k+1}} \right \| \\
                            &\leq \| \phi \| \sum_{k=0}^\infty \frac{\| T \|^k}{| \lambda|^{k+1}} \\
                            &= \frac{ \| \phi \|}{ |\lambda | - \| T \|} \rightarrow 0
        \end{align*} as $|\lambda| \rightarrow \infty$.  So $f_\phi$ is bounded, entire, and thus $f_\phi = c$ by Lioville's theorem.  By the above, $f_\phi(\lambda) = 0$ for all $\lambda$.  Hence $\phi(R(\lambda)) = 0$ for all $\lambda, \phi$.
        
        Thus from Hahn-Banach, $R(\lambda) = 0$ for all $\lambda$ which is a contradiction, as the zero operator is not invertible if $X \neq \{ 0 \}$.   
    \end{proof}
\end{proof}

% section lecture_18_wednesday_4_may (end)
\section{Lecture 19 - Monday 9 May} % (fold)
\label{sec:lecture_19_monday_9_may}
\begin{thm}[Spectral mapping theorem (polynomials)]
    Let $T$ be an $n \times n$ matrix over $\Com$.  IF we know all the eigenvalues of $T$, then we know the eigenvalues of every polynomial $p(T) = a_0 + a_1 T + \dots + a_n T^n$.  Specifically, \[
        \{ \text{eigenvalues of $p(T)$} \} = \{ p(\lambda) \given \text{$\lambda$ is an eigenvalue of $T$} \}
    \] Therefore \[
        \sigma(p(T)) = p(\sigma(T)).
    \]  This is called the \textbf{spectral mapping theorem} (for matrices/polynomials). 
    
    This also holds for $X$ Banach over $\Com$, and $T \in \mathcal L(X)$.
\end{thm}

\begin{lem}
    Let $\Com[t]$ be the algebra of polynomials in $t$ with complex coefficients.  Multiplication is defined as usual.
\end{lem}

\begin{lem}
    Let $X$ be Banach over $\Com$.  Let $T \in \mathcal L(X)$.  Then \mapping{\phi}{\Com[t]}{\mathcal L(X)}{p}{p(T)} is an algebra homomorphism (multiplication corresponds to composition in $\mathcal L(X)$.)
\end{lem} 
\begin{proof}
    Simply check \begin{align*}
        \phi(p_1 + p_2) = \phi(p_1) + \phi(p_2) \\
        \phi(p_1 p_2) = \phi(p_1)\phi(p_2) \\
        \phi(\alpha p) = \alpha \phi(p)
    \end{align*} for all $p_1, p_2, p \in \Com[t], \alpha \in \Com$.  
\end{proof}
\begin{thm}
    Let $X$ be Banach over $\Com$, and let $T \in \mathcal L(X)$.  Then \[
        \sigma(p(T)) = p(\sigma(T)).
    \]
\end{thm}
\begin{proof}
    If $p = c$ is constant, then $p(T) = cI$ has spectrum \[
        \sigma(p(T)) = \sigma(cI) = \{ c \}
    \]  On the other hand, \[
        p(\sigma(T)) = \{ c \}
    \]  
    Now, suppose that $p$ is non constant.  Let $\mu \in \Com$ fixed.  By the fundamental theorem of algebra, we can factorise $\mu - p(t)$ as \[
        \alpha( t - \lambda_1)^{m_1} \dots (t - \lambda_n)^{m_n}
    \] where $\lambda_1, \dots, \lambda_n$ are the distinct roots of $\mu - p(t)$.  Note that $\mu = p(\lambda_i)$ for each $i$.  Applying $\psi: \Com[t] \rightarrow \mathcal L(X)$ from above, we have \begin{align*}
        \mu I - p(T) = \alpha(T- \lambda_1 I)^{m_1} \dots (T - \lambda_n I)^{m_n}
    \end{align*}
    \begin{exer}
        If $T_1, \dots, T_n \in \mathcal L(X)$ which commute with each other, then $T_1 \dots T_n$ is invertible if and only if the individual elements are invertible.  
    \end{exer}
    
    We know \begin{align*}
        \mu \in \sigma(p(T)) &\iff \mu - p(T) \, \text{is not invertible} \\
            &\iff T - \lambda I \, \text{non invertible for some $i$} \\
            &\iff \lambda \in \sigma(T) \, \text{for some $i$} \\
            &\iff \mu = p(\lambda_i) \in p(\sigma(T))
    \end{align*} and so \[
        \sigma(p(T)) = p(\sigma(T))
    \] 
\end{proof}

\begin{defn}[Spectral radius]
Let $X \neq \{ 0 \}$ be a Banach space over $\Com$.  The \textbf{spectral radius} of $T \in \mathcal L(X)$ is
\begin{align*}
    r(T) &= \sup \{ | \lambda | \given \lambda \in \sigma(T) \} \\
    &= \max \{ |\lambda | : \lambda \in \sigma(T)\}
\end{align*}
\end{defn}
\begin{note}
    \[
        r(T) \leq \| T \|
    \] since $\sigma(T) \subseteq \{ \lambda \in \Com \given | \lambda | \leq \| T \| \}$.  Strict inequality can (and often does) occur.
\end{note}

\begin{exmp}
    Let \[
        T = \begin{pmatrix}
            0 & 1 \\
            0 & 0 
        \end{pmatrix}.
    \]  Then consider $T : \Com^2 \rightarrow \Com^2$ where $\| (x, y) \|_2 = \sqrt{|x|^2 + |y|^2}$.  Then \begin{align*}
        \| T \| &= \sup \{ \| Tx \|_2 \given x \in \Com^2 \} \\
                &= \sqrt{\lambda_{max} (T^* T)} 
    \end{align*} where \[
        T^* = \begin{pmatrix}
            0 & 0 \\
            1 & 0
        \end{pmatrix}
    \] is conjugate transpose.  Then $\| T \| = 1$.  But $\sigma(T) = \{ 0 \}$, and so $r(T) = 0 < 1 = \| T \|$.  
\end{exmp}

\begin{thm}[Gelfand, 1941]
    Let $X \neq \{ 0 \}$ be Banach over $\Com$, and let $T \in \mathcal L(X)$.  Then \begin{align*}
        r(T) = \lim_{n \rightarrow \infty} \| T^n \|^{1/n}.
    \end{align*} In particular, the limit exists.  
\end{thm}
\begin{proof}
    By the spectral mapping theorem, \[
        \sigma(T^n) = \{\sigma(T)\}^n = \{ \lambda^n \given | \lambda \in \sigma(T) \}.
    \]  So \begin{align*}
        r(T) &= r(T^{n})^{1/n} \\
            &\leq \| T^n \|^{1/n}.  
    \end{align*} So \[
        r(T) \leq \liminf_{n \rightarrow \infty} \| T^n \|^{1/n}
    \]  
    
    Now, we must show that \[
        \limsup_{n \rightarrow \infty} \| T^n \|^{1/n} \leq r(T).
    \]
    Let $\phi \in \mathcal L(X)$ and let \mapping{f_\phi}{\rho(T)}{\Com}{\lambda}{\phi((\lambda I - T)^{-1})}
    
    We saw that $f_\phi$ is analytic on $\rho(T)$.  We also have \[
        f_\phi(\lambda) = \sum_{n = 0}^\infty \frac{1}{\lambda^{n+1}} \phi(T^n) \tag{$\star$}
    \] if $| \lambda | > \| T \|$.  By general theory of Laurent series, ($\star$) actually holds for all $\lambda \in \rho(T)$.  In particular, it holds if $| \lambda | > r(T)$. 

Thus, \begin{align*}
    \lim_{n \rightarrow \infty} \frac{1}{\lambda^{n+1}}\phi(T^n) = 0 \quad \boxed{|\lambda| > r(T)}
\end{align*}  Sp for each $\phi \in \mathcal L(X)'$, and each $|\lambda| > r(T)$, there is $C_{\lambda, \phi}$ such that \[
    \left| \phi\left( \frac{1}{\lambda^{n+1}} T^n \right) \right| \leq C_{\lambda, \phi} \quad \forall n \geq 0
\]  Then by the principle of uniform boundedness, there exists a constant $C_\lambda$ such that \[
    \left\| \frac{1}{\lambda^{n+1}} T^n \right\| \leq C_\lambda \quad \forall n \geq 0
\]  So $\| T^n \|^{1/n} \leq |\lambda | (C_\lambda | \lambda|)^{1/n}$, which gives \[
    \limsup_{n \rightarrow \infty} \| T^n \|^{1/n} \leq \lambda
\] for all $| \lambda | > r(T)$.  So \[
    \limsup_{n \rightarrow \infty} \| T^n \|^{1/n} \leq r(T)
\]  We used the following lemma.

\begin{lem}
    Let $X$ be a normed vector space, $A \subseteq X$ a subset.  We say that \begin{enumerate}[(1)]
        \item $A$ is \textbf{bounded} if there exists $C > 0$ with $\| x \| \leq C$, for all $x \in A$.
        \item $A$ is \textbf{weakly bounded} if for each $\phi \in X'$, there exists $C_\phi > 0$ such that \[
            | \phi(x) | \leq C_\phi
        \] for all $x \in A$.
    \end{enumerate}
    
    Then we have \[
        \text{$A \subseteq X$ is bounded}  \iff \text{weakly bounded}
    \]
\end{lem}
\begin{proof}
    $A$ bounded $\Rightarrow$ $\| x \| \leq C$ for all $x \in A$ $\Rightarrow$ $|\phi(x)| \leq \| \phi \| \| x \| \leq \|\phi \| C$.  So $A$ is weakly bounded.
    
    Now, suppose $A$ is weakly bounded.  For each $x \in X$, let $\hat x \in X''$ with \[
        \hat x(\phi) = \phi(x).
    \]  So $| \hat x(\phi) | \leq C_\phi$ for all $x \in A$.  By the principle of uniform boundedness, \[
        \| \hat x \| \leq C
    \] for all $x \in A$, and since $\| \hat x \| = \| x \|$.  Thus $A$ is bounded.  
\end{proof}
\end{proof}  
% section lecture_19_monday_9_may (end)

\section{Lecture 20 - Wednesday 11 May} % (fold)
\label{sec:lecture_20_wednesday_11_may}

We now turn to compact operators.  In general, calculating $\sigma(T)$ is difficult, but for compact operators on a complex Banach space, we have a fairly explicit theory.

\begin{thm}
    Let $X$ be a complex Banach space, with $\dim(X) = \infty$.  Let $T : X \rightarrow X$ be a compact operator.  Then \begin{enumerate}[(1)]
        \item $0 \in \sigma(T)$.  
        \item $\sigma(T) \backslash \{ 0 \} = \sigma_p(T) \backslash \{ 0 \}$, that is, each $\lambda \in \sigma(T) \backslash \{ 0 \}$ is an eigenvalue of $T$ ($0$ may or may not be an eigenvalue.)
        \item We are in exactly one of the cases:
         \begin{itemize}
            \item $\sigma(T) = \{ 0 \}$.
            \item $\sigma(T) \backslash \{ 0 \}$ is finite (nonempty).
            \item $\sigma(T) \backslash \{ 0 \}$ is a sequence of points converging to $0$.  
         \end{itemize}
         \item Each $\lambda \in \sigma(T) \backslash \{ 0 \}$ is isolated, and the eigenspace $\ker(\lambda I - T)$ is finite dimensional.  
    \end{enumerate}  
    where $\sigma_p(T)$ is the \textbf{point spectrum of $T$}, where \begin{align*}
        \sigma_p(T) &= \{ \lambda \in \K \given \text{$\lambda I - T$ is not injective}\} \\
                    &= \{ \lambda \in \K \given \text{there exits nonzero vector $x$ with $(\lambda I - T)x = 0$}\} \\
                    &= \{ \text{eigenvalues of $T$} \}
    \end{align*}
    
\end{thm}
\begin{proof}
    We shall prove these results next week.
\end{proof}

\begin{defn}
    Let $X, Y$ be normed vector spaces.  An operator $T : X \rightarrow Y$ is \textbf{compact} if $T$ is linear, and if $B \subseteq X$ is bounded then $T(B) $ is relatively compact (a set is relatively compact if its closure is compact.)  Symbolically, \[
        \text{$B\subseteq X$ bounded} \Rightarrow \text{$\overline{T(B)}$ compact}
    \]
\end{defn}

\begin{lem}
    IF $T$ is compact, then $T$ is continuous.
\end{lem}
\begin{proof}
    The closed ball $B  = \{ x \in X \given \| x \| \leq 1 \}$ is bounded, and so if $T$ is a compact operator, then $\overline{T(B)}$ is compact, and hence bounded.  Hence $\| Tx \| \leq M$ for all $\| x \| \leq 1$, so $T$ is continuous, with $\| T \| \leq M$.  
\end{proof}

We now recall definitions of compactness
\begin{thm}[Characterisations of compactness]
    Let $X$ be a metric space. The following are equivalent.  
    \begin{enumerate}[(1)]
        \item $X$ is \textbf{compact} (every open cover has a finite subcover).
        \item $X$ is \textbf{sequentially compact} (every sequence in $X$ has a convergent subsequence)
    \end{enumerate}
\end{thm}

\begin{lem}
    Let $X$ be a compact set.  Let $Y \subseteq X$. If $Y \subseteq X$ is closed, then $Y$ is compact.
\end{lem}

\begin{lem}
    Let $V$ be a finite dimensional vector space.  If $X \subseteq V$ is closed and bounded, then $X$ is compact.
\end{lem}

\begin{thm}[Characterisations of compact operators]
    \label{thm:charcompact}
    Let $X, Y$ be normed vector spaces over $\K$.  Let $T \in \mathcal L(X,Y)$.  Then the following are equivalent.
    \begin{enumerate}[(a)]
        \item $T$ is compact.
        \item $\overline{T(B)}$ is compact, where $B = \{ x \in X \given \| x \| \leq 1 \}$.  
        \item If $(x_n)_{n \geq 1}$ is bounded in $X$, then $(Tx_n)_{n \geq 1}$ has a convergent subsequence (\textbf{sequentially compact}).
    \end{enumerate}
\end{thm}

\begin{proof}
    $(a) \Rightarrow (b)$ by definition.
    
    $(b) \Rightarrow (a)$.  Suppose $(b)$ holds.  Let $B_1 \subseteq X$ be bounded.  Then $B_1 \subseteq \alpha B$ for some $\alpha > 0$.  So \[
        \overline{T(B)} \subseteq \overline{T(\alpha B)} = \alpha \overline{T(B)}
    \] which is a closed subset of a compact set, and hence compact.  
    
    $(a) \Rightarrow (c)$.  Suppose $T$ is compact.  Let $(x_n)_{n \geq 1}$ be bounded sequence in $X$.  Then $T(B) = \{ Tx_n \given n \geq 1 \}$ is relatively compact.  So $\overline{T(B)}$ is compact, and hence is sequentially compact, and so has a convergence subsequence.
    
    $(c) \Rightarrow (a)$.  Let $B \subseteq X$ be bounded.  Let $(y_n)_{n \geq 1}$ be a sequence in $T(B)$.  Then there is $x_n \in B$ with $Tx_n = y_n$.  So $(x_n)_{n \geq 1}$ is a bonded sequence.  By assumption $(Tx_n)_{n \geq 1}$ has a convergent subsequence.  So $\overline{T(B)}$ is sequentially compact, and hence compact.
\end{proof}

\begin{cor}
    The set $\{ \text{compact operators $T : X \rightarrow Y$}\}$ is a vector space.  That is, if $T_1, T_2$ are compact, then $T_1 + T_2$ and $\alpha T_1$ are compact.  
\end{cor}

\begin{proof}
    Exercise.  Use $(c)$ from the characterisation of compact operators.
\end{proof}

\begin{cor}
    \[
        \mathcal K(X,Y) \subseteq \mathcal L(X, Y) \subseteq \text{Hom}(X,Y)
    \] where $\mathcal K(X,Y)$ is the set of compact operators $T : X \rightarrow Y$. 
\end{cor}

\begin{exmp}[Finite rank operators]  
    Let $X, Y$ be normed vector spaces, and let $T \in \mathcal L(X,Y)$.  If $\dim(\im T) < \infty$, then $T$ is said to have \textbf{finite rank.}  Then if $T$ has finite rank, then $T$ is compact.
\end{exmp}

\begin{proof}
    Let $(x_n)$ be a bounded sequence in $X$.  Then $\| Tx_n \| \leq \| T \| \| x_n \|$ so $(Tx_n)$ is a bounded sequence in $\im T$.  But $\im T$ is finite dimensional, and so $\overline{ \{ Tx_n \given n \geq 1 \}}$ is compact (closed and bounded), and so $(Tx_n)_{n \geq 1}$ has a convergent subsequence.  By $(c)$ in Theorem \ref{thm:charcompact}, $T$ is compact. 
\end{proof}

\begin{lem}
    Let $X, Y$ be normed vector spaces.  If $T \in \mathcal L(X,Y)$ has finite rank, then there exists $y_1, \dots, y_n \in \im T$ and $\phi_1, \dots, \phi_n \in X'$ with $Tx = \sum_{j=1}^n \phi_j(x) y_j$ for all $x \in X$, with $n = \dim( \im T)$. 
\end{lem}

\begin{proof}
    Choose a basis $y_1, \dots, y_n$ of $\im T$.  For each $j = 1, \dots, n$, define $\alpha_j \in (\im T)'$ by \[
        \alpha_j(a_1 y_1 + \dots + a_n y_n) = a_j
    \] i.e. coordinate projection.  By Hahn-Banach, we can extend $a_j$ to a continuous linear functional $\tilde a_j \in Y'$.  Let $\phi_j = \tilde a_j \circ T : X \rightarrow \K$.  So $\phi_j \in X'$.  Since \[
         y = \sum_{j=1}^n \tilde a_j(y) y_j \quad \forall y \in \im T
    \] 
    
    we have \begin{align*}
        Tx  &= \sum_{j= 1}^n \tilde a_j (Tx) y_j \\
            &= \sum_{j=1}^n (\alpha_j \circ T)(x) y_j    \\
            &= \sum_{j=1}^n \phi_j(x) y_j \quad \forall x \in X.
    \end{align*}
\end{proof}
% section lecture_20_wednesday_11_may (end)

\section{Lecture 21 - Monday 16 May} % (fold)
\label{sec:lecture_21_monday_16_may}


Recall that the closed unit ball in $X$ is compact if and only if $\dim(X) < \infty$.  Then it follows that the identity map $I : X \rightarrow X$ is compact if and only if $\dim(X) < \infty$.  Hence, \[
    \mathcal K(X) \subsetneq \mathcal L(X) \subsetneq \text{Hom}(X, X) 
\] when $\dim(X) = \infty$.    

Consider a sequence of compact operators $T_n$.  If $T_n$ is compact and $T_n \rightarrow T$, then $T$ is compact.  

\begin{lem}[Riesz's Lemma]
    Let $X$ be a normed vector space.  Let $Y \subsetneq X$ be a proper \textbf{closed} subspace.  Let $\theta \in (0, 1)$ be given. Then there exists $x$ with $\| x \| = 1$ such that $\| x - y \| \geq \theta$ for all $y \in Y$.  
\end{lem}
\begin{proof}
    Pick any $z \in X \backslash Y$.  Let $\alpha = \inf_{y \in Y} \| z - y \| > 0$ since $Y$ is closed.  Then by the definition of the infimum, there is $y_0 \in Y$ with $\alpha \leq \| z - y_0 \| \leq \frac{\alpha}{\theta}$.  Now let $x = \frac{z - y_0}{\| z - y_0 \|}$.  Then $\| x \| = 1$.  
    
    Now, \begin{align*}
        \| x - y \| &= \left \| \frac{z - y_0}{\| z - y_0 \|} - y \right \| \\
                    &= \frac{1}{\| z - y_0 \|} \left \| z - y_0 + \| z - y_0 \| y \right \| \\
                    &\geq \frac{\theta}{\alpha} \alpha = \theta
    \end{align*}
\end{proof}

\begin{cor}
    Let $X$ be a normed vector space.  The closed unit ball $\overline B(0, 1)$ is compact if and only if $\dim(X) < \infty$.  
\end{cor}
\begin{proof}
    If $\dim(X) < \infty$ then $\overline B(0, 1)$ is compact (since closed and bounded if and only if compact in finite dimensions).  Now suppose $\dim(X) = \infty$.  Build a sequence $(x_n)$ with $\| x_n \| = 1$ with no convergent subsequence.  Choose finite dimensional subspaces \[
        \{ 0 \} = X_0 \subsetneq X_1 \subsetneq X_2 \subsetneq \dots
    \]  
    
    These are all closed (finite dimensional spaces are complete, and hence closed).  Use the lemma to choose $x_k \in X_k$ with $\| x_k \| = 1$, $\| x_k - x \| \geq \frac{1}{2}$ for al $ x \in X_{k-1}$.  So $x_k - x \| \geq \frac{1}{2}$ for all $x \in X_j (j \leq k - 1)$.  So $\| x_n - x_m \| \geq \frac{1}{2}$ for all $m , n \geq 1$.  So $(x_n)$ has no convergent subsequence, and so $\overline B(0, 1)$ is not compact.  
\end{proof}
\begin{cor}
    $I : X \rightarrow X$ is compact if and only if $\dim(X) < \infty$.  
\end{cor}
\begin{proof}
    Recall $T$ is compact if and only if $T(\overline B(0, 1))$ is relatively compact.  
\end{proof}

\subsection{Limits of compact operators} % (fold)
\label{sub:limits_of_compact_operators}
One way to show that an operator is compact is to apply the following.  
\begin{prop}
    Let $X$ be a normed vector space, and let $Y$ be Banach.  Suppose that $T_n \in \mathcal K(X, Y)$ for each $n \geq 1$.  If $T_n \rightarrow T$ (in operator norm, $\| T_N - T \| \rightarrow 0$) then $T$ is compact.  
\end{prop}
\begin{proof}
    Let $(x_n)$ be a bounded sequence in $X$.  We now construct a subsequence $(x'_n)$ for which $(Tx'_n)$ converges.  \begin{itemize}
        \item Since $T_1$ is compact, $(x_n)$ has a subsequence $x^{(1)}_n$ such that $(T_1 x^{(1)}_n)$ converges. 
        \item Since $T_2$ is compact and $x^{(1)}_n$ is bounded, there is a subsequence $x_n^{(2)}$ such that $T_2 x^{(2)}_n$ converges. 
        \item Continuing, we can form a subsequence $x^{(k)}_n$ such that $T_k x^{k}_n$ converges. 
    \end{itemize}

Let $x_n' = x_n^{(n)}$.  Then $(x'_n)$ is a subsequence of $(x_n^{(1)})$, and $(x'_n)_{n \geq 2}$ is a subsequence of $(x_n^{(2)})$, etc.  So for each fixed $k \geq 1$, $(T_k x'_n)$ converges.  

We now show $T x'_n$ is Cauchy, and hence converges.  We have \begin{align*}
    \| Tx'_m - T x'_n \| \leq \| T x'_m - T_k x'_m \| + \| T_K x'_m - T_k x'_n \| + T_k x'_n - T x'_n \|
\end{align*} where $k$ is to be chosen.  Suppose $\| x_n \| \leq M$ for all $n \geq 1$.  Then \begin{align*}
    \| Tx'_m - T x'_n \| \leq 2 M \| T - T_k \| + \| T_k x'+m - T_k x'_n \|
\end{align*} Let $\epsilon > 0$ be given. Since $\| T - T_k \| \rightarrow 0$ as $ k \rightarrow \infty$, fix a $k$ for which $\| T - T_k \| \leq \frac{\epsilon}{3M}$.  For this fixed $k$, we know $(T_k x'_n)$ converges, and so is Cauchy.  So there exists $N < 0$ such that $\| T_k x'm - T_k x'_n\| < frac{\epsilon}{3}$ for all $m,n < N$.  Hence $\|T x'_m - Tx'_n \| \leq \frac{2M}{\epsilon}{3M} + \frac{\epsilon}{3} = \epsilon$ for all $m , n > N$, so is Cauchy, and so converges. 
\end{proof}

\begin{exmp}
    Let $K(x, y) \in L^2(\R^2)$.  Define $T : L^2(\R) \rightarrow  L^2(\R)$ by \[
        Tf(x) = \int_\R K(x, y) f(y) \, dy
    \] (Hilbert-Schimidt Integral operator)
\end{exmp}
\begin{prop}
    $T$ is compact.  
\end{prop}
\begin{proof}
    Note that $\| Tf \|_2 \leq \| K \|_2 \| f \|_2$ for all $f \in L^2(\R)$, where $\| K \|_2 = \left( \iint_{\R^2} |K(x, y)|^2 \, dx \, dy \right)^{1/2}$.  So $T$ is continuous, with $\| T \| \leq \| K \|_2$.  We now exhibit $T$ as a limit of finite rank (hence compact) operators, with $T_n : L^2(\R) \rightarrow L^2(\R)$.  Once can see that there is a sequence $K_n \in L^2(\R^2)$ of the form \[
        K_n(x, y) = \sum_{k=1}^{N_n} \alpha_k^{(n)}(x) \beta_{k}^{(n)}(y)
    \] with $K_n \rightarrow K$ in $L^2(\R^2)$.  Then $\| T_n - T \| \leq \| K_n - K \|_2 \rightarrow 0$, and so $T_n \rightarrow T$.  Hence 
    \begin{align*}
        T_n f(x) \sum_{k=1}^{N_n} \int_\R \alpha_k^{(n)}(x) \beta_k^{(n)}(y) f(y) \, dy \\
        &= \sum_{k=1}^{N_n} \iprod{f, \overline{\beta_k^{(n)}}} \alpha_k^{(n)} (x) 
    \end{align*}  and so $T_nf = \sum_{k=1}^{N_n} \iprod f, \overline{\beta_k^{(n)}} \alpha_k^{(n)}$ from which we use that $T_n$ has finite rank.  
\end{proof}

% subsection limits_of_compact_operators (end)

% section lecture_21_monday_16_may (end)


\section{Lecture 22 - Wednesday 18 May} % (fold)
\label{sec:lecture_22_wednesday_18_may}

\begin{thm}
Let $X$ be a complex Banach space, with $\dim(X) = \infty$.  Let $T : X \rightarrow X$ be a compact operator.  Then \begin{enumerate}[(1)]
    \item $0 \in \sigma(T)$.  
    \item $\sigma(T) \backslash \{ 0 \} = \sigma_p(T) \backslash \{ 0 \}$, that is, each $\lambda \in \sigma(T) \backslash \{ 0 \}$ is an eigenvalue of $T$ ($0$ may or may not be an eigenvalue.)
    \item We are in exactly one of the cases:
     \begin{itemize}
        \item $\sigma(T) = \{ 0 \}$.
        \item $\sigma(T) \backslash \{ 0 \}$ is finite (nonempty).
        \item $\sigma(T) \backslash \{ 0 \}$ is a sequence of points converging to $0$.  
     \end{itemize}
     \item Each $\lambda \in \sigma(T) \backslash \{ 0 \}$ is isolated, and the eigenspace $\ker(\lambda I - T)$ is finite dimensional.  
\end{enumerate}  
where $\sigma_p(T)$ is the \textbf{point spectrum of $T$}, where \begin{align*}
    \sigma_p(T) &= \{ \lambda \in \K \given \text{$\lambda I - T$ is not injective} \\
                &= \{ \lambda \in \K \given \text{there exits nonzero vector $x$ with $(\lambda I - T)x = 0$} \\
                &= \{ \text{eigenvalues of $T$} \}
\end{align*}
\end{thm}

Compact operators are very well behaved with respect to composition.  
\begin{prop}
    Let $X, Y, Z$ be normed vector spaces.  
    \begin{enumerate}[(a)]
        \item If $T \in \mathcal K(X, Y)$ and $S \in \mathcal L(Y, Z)$, then $
            ST \in \mathcal K(X, Z)
        $.
        \item If $S \in \mathcal L(X, Y)$ and $T \in \mathcal K(Y, Z)$, then $
            TS \in \mathcal K(X, Z)
        $.
    \end{enumerate}
\end{prop}
\begin{proof}
    \begin{enumerate}[(a)]
        \item Let $(x_n)$ be a bounded sequence in $X$.  Since $T$ is compact, $Tx_n$ has a convergent subsequence, say $T_{x_{n_k}} \rightarrow y \in Y$. Then $(STx_n)$ has a convergent subsequence, namely $STx_{n_k} = S(T_{n_k}) \rightarrow Sy$  by continuity of $S$.  So $ST$ is compact. 
        \item Let $B \subseteq X$ be bounded.  Then $S(B)$ is bounded in $Y$, as $S$ is continuous.  So $TS(B) = T(S(B))$ is relatively compact since $T$ is compact. Hence $TS$ is compact.
    \end{enumerate}
\end{proof}

\begin{cor}[Part (1) of theorem]
    If $X$ is infinite dimensional Banach space, then $0 \in \sigma(T)$.  
\end{cor}
\begin{proof}
    If $0 \notin \sigma(T)$ then $T$ is invertible.  By bounded inverse theorem $T^{-1}$ is continuous, and then $I = T T^{-1}$ is compact, which is a contradiction.
\end{proof}

\begin{thm}[Part (3) of theorem]
    Let $X$ be a normed vector space.  Let $T \in \mathcal K(X)$.  Then $T$ has at most countably many eigenvalues.  If $T$ has infinitely many eigenvalues, then they can be arranged in a sequence converging to zero.    
\end{thm}
\begin{proof}
    We show that for each $N > 0$, we have \[
        \#\{ \lambda \in \sigma_p(T) \given | \lambda | \geq N \} < \infty \tag{$\star$}
    \] 
     Suppose that there is $N > 0$ such that $(\star)$ fails.  So $\lambda_1, \lambda_2, \dots$ are distinct eigenvalues with $|\lambda_n | \geq N$ for $n = 1, 2, \dots$.  Let $x_n \neq 0$ be an eigenvector.  $Tx_n = \lambda_n x_n$, $n = 1, 2, \dots$.  Let $X_n = \spans\{ x_1, \dots, x_n \}$.  Since $\{ x_n \given \geq 1 \}$ are linearly independent, we have \[
        X_1 \subsetneq X_2 \subsetneq \dots
    \] and each $X_n$ is closed (finite dimensional). 
    
     By Reisz's Lemma from previous lecture, choose $y_n \in X_n$ such that $\| y_n \| = 1$ and $\| y_n - x \| \geq \frac{1}{2}$ for all $x \in X_{n-1}$.  So $(y_n)$ is bounded in $X$.  We show that $Ty_n$ has no convergence subsequence, contradicting compactness of $T$.  
    
    Let $ m  > n$.  Then \begin{align*}
        \| Ty_m - Ty_n \|   &= \left\| \lambda_m y_m - \left( \lambda_m y_m - Ty_m + Ty_n \right) \right| \\
                            &= |\lambda_m | \left\| y_m - (\text{something in $X_{m-1}$}) \right\| \\
                            &\geq \frac{1}{2}|\lambda_m| \geq \frac{1}{2}N
    \end{align*} as required. 
    
    Note that $y_m = a_1 x_1 + \dots + a_m x_m$.  Then \begin{align*}
        \lambda_m y_m - T y_m &=  \lambda_m a_1 x_1 + \dots + \lambda_m a_m x_m - (a_1 \lambda_1 x_1 + \dots + a_m \lambda_m x_m) \\
        &= a_1(\lambda_m - \lambda_1) x_1 + \dots + a_{m-1}(\lambda_m - \lambda_{m-1}) x_{m-1} \in X_{m-1}
    \end{align*} and $T y_n \in X_{m-1}$ since $n< m$.
    
\end{proof} 

\subsection{Projections} % (fold)
\label{sub:projections}

\begin{defn}[Projection operator]
    Let $X$ be a vector space.  A linear operator $P : X \rightarrow X$ is called a projection if $P^2 = P$.
\end{defn}
\begin{prop}
    If $P : X \rightarrow X$ is a projection then $I - P$ is a projection, and \[
        \im I - P= \ker P, \quad \ker I - P = \im P
    \]
\end{prop}

\begin{proof}
    If $P^2 = P$ then $(I - P)^2 = I - 2P + P^2 = I - P$ and so $I -  P$ is a projection.  Let $x \in \im I-P$  Then $x = (I - P)y$ for some $y \in X$.  So $P x = P(I - P)y = (P - P^2) y = 0$.  So $x \in \ker P$ and $\im I - P \subseteq \ker P$.  If $x \in \ker P$ the $Px = 0$.  So $(I - P) x = x$, and $x \in \im(I - P)$. 
\end{proof}

\begin{defn}[Direct sum]
    Let $X$ be a vector space, and let $X_1, X_2$ be subspaces.  Then $X = X_1 \oplus X_2$ (direct sum) if \[
        X = X_1 + X_2
    \] and $X_1 \cap X_2 = \{ 0 \}$.  Equivalently, $X = X_1 \oplus X_2$ if and only if each $x \in X$ can be written in exactly one way as $x = x_1 + x_2$ with $x_1 \in X_1, x_2 \in X_2$.  
\end{defn}
\begin{thm}[Equivalence of direct sums and projections]
    Let $X$ be a vector space.  \begin{enumerate}[(a)]
        \item If $P : X \rightarrow X$ is a projection, then \[
            X = (\im P) \oplus (\ker P) 
        \] 
        \item If $X = X_1 \oplus X_2$, there exists a unique projection with \[
            \im P = X_1, \quad \ker P = X_2.
        \] Specifically, $Px = x_1$ if $x = x_1 + x_2$. 
    \end{enumerate}
\end{thm}

\begin{proof}
    \begin{enumerate}[(a)]
        \item Let $P : X \rightarrow X$ be a projection.  Then we show $X = (\im P) \oplus (\im I - P)$, $x = Px + (I - P) x$.  This shows that $X = \im P + \im I - P$.  If $x \in \im P \cap \ker P$ then $x = Py$ and $Px = 0$.  Hence, $Px = P^2 y = P^y = 0$ and so $ x = 0$.
        \item Exercise.  
    \end{enumerate}
\end{proof}

\begin{prop}
    Let $X$ be Banach.  Let $X = X_1 \oplus X_2$.  Let $P : X \rightarrow X$ be the corresponding projection operator.  Then \[
        P \in \mathcal L (X) \iff \text{$X_1, X_2$ closed}
    \]
\end{prop}
\begin{proof}
    $(\Rightarrow)$.  Suppose $P$ is continuous.  Then $X_1 = \im P = \ker I - P$ and $X_2 = \ker P$ are both closed.  For example, if $x_n \in \ker P$ and $x_n \rightarrow x$, then $0 = P x_n \rightarrow Px$ and so $x \in \ker P$.  
    
    $(\Leftarrow)$.  Suppose that $X_1, X_2$ are closed.  Since $X = X_1 \oplus X_2$, we can define a new norm $\| \cdot \|'$ by $\| x \|' = \| x_1 \| + \| x_2 \|$ where $x = x_1 + x_2$.  
    \begin{exer}{\ }
        \begin{enumerate}[(a)]
            \item Show that $\| \cdot \|'$ is a norm.
            \item Show that $(X, \| \cdot \|')$ is Banach.  This relies on the fact that $(X, \| \cdot \|)$ is Banach and $X_1, X_2$ are closed. 
        \end{enumerate}
    \end{exer}
    
    Note that $\| x \| = \| x_1 + x_2 \| \leq \| x_1 \| + \| x_2 \| = \| x \|'$, and so by a corollary to the open mapping theorem, there is a $c > 0$ with $\| x \|' \leq c \| x \|$ for all $x \in X$, and so \[
        \| Px \| = \| x_1 \| \leq \| x_1 \| + \| x_2 \| = \| x \|' \leq c \| x \|
    \] and hence $P$ is continuous.  
\end{proof}
% subsection projections (end)


% section lecture_22_wednesday_18_may (end)

\section{Lecture 23 - Monday 23 May} % (fold)
\label{sec:lecture_23_monday_23_may}

\begin{cor}
    Let $X$ be Banach, and let $M$ be a finite dimensional subspace.  Then there exists a \textbf{closed} $N$ with \[
        X = M \oplus N.
    \]
\end{cor}
\begin{proof}
    Let $v_1, \dots, v_n$ be a basis of $M$.  Define, for each $ j = 1, \dots, n$, $\phi_j \in M'$ by $\phi_j(a_1 v_1 + \dots + a_n v_n) = a_j$.  Then using Hahn-Banach to extend $\tilde \phi_j \in X'$.  Let $P : X \in X$ be defined by \[
        Px = \sum_{j =1 }^n \tilde \phi_j(x) v_j.
    \]  Then we need only check that $P$ is linear and continuous, $\im P = M$, and $P^2 = P$. Now take $N = \ker P$ and then $X = M \oplus N$.
\end{proof}.


We are now ready to prove the following theorem.

\begin{thm}
    Let $X$ be Banach, and let $T \in \mathcal K(X)$, and let $\lambda \in \K \backslash \{ 0 \}$.  For all $k \in \N$, we have \begin{enumerate}[(a)]
        \item $\underbrace{\ker(\lambda I - T)^k}_{\text{generalised eigenspace}}$ is finite dimensional.
        \item $\im(\lambda I - T)^k$ is closed.   
    \end{enumerate}
\end{thm}
\begin{proof}
    \textbf{Reductions}.  Since $\ker(\lambda I - T)^k = \ker(I - \lambda^{-1}T)^k$, and similarly for the image, by replacing $T \in \mathcal K(X)$ by $\lambda T \in \mathcal K(X)$, we can assume that $\lambda = 1$.
    
    Also, we have \begin{align*}
        (I - T)^k   &= \sum_{n=0}^k {k \choose n} (-1)^n T^n \\
                    &= I - T \underbrace{\sum_{n = 1}^k {k \choose n} (-1)^{n-1} T^{n-1}}_\text{continuous}  \\
                    &= I - \tilde T.
    \end{align*} where $\tilde T$ is the composition of compact and continuos operators, and so is compact.  So we can take $\lambda = 1, k = 1$.  
    
    \begin{enumerate}[(a)]
        \item The closed unit ball in $\ker I - T$ is \begin{align*}
        \{ x \in \ker I - T \given \| x \| \leq 1 \} &= \{ Tx \given x \in \ker I - T, \ | x \| \leq 1 \} \\
        &\subseteq \overline{T (\overline B(0, 1))}
        \end{align*} which is compact as $T$ is compact.  Hence, the closed unit ball in $\ker I - T$ is compact, and thus $\ker I - T$ is finite dimensional.
        \item Let $S = I - T$.  We then need to show that $\im S$ is closed.  Since $\ker S$ is finite dimensional from above, there is a \textbf{closed} subspace $N$ with \[
            X = (\ker S) \oplus N
        \]  Note that $\im S = S(X) = S(N)$, and that $S |_N : N \rightarrow X$ is injective. 
        
        Suppose that $S(N)$ is not closed.  So there is a sequence $(x_n)$ in $N$ such that $Sx_n \rightarrow y \in X \backslash S(N)$. Then there are two cases
        \begin{case}[$\| x_n \| \rightarrow \infty$]  Let $y_n = \frac{1}{\| x_n \|} x_n$.  Then $Sy_n = \frac{1}{\| x_n \|} S x_n \rightarrow 0$.  But $(y_n)_{ n \geq 1}$ is bounded in $X$, and so there exists a subsequence $y_{n_k}$ such that $T y_{n_k} \rightarrow z$ (as $T$ is compact).  Hence $y_{n_k} = S y_{n_k} + T y_{n_k} \rightarrow 0 + z$.  Thus $z \in N$ (as $y_{n_k} \in N$, and $N$ is closed), and $\| z \| = 1$.  
            
            So $S y_{n_k} \rightarrow 0$, but $S y_{n_k} \rightarrow Sz$ with $z \in N \backslash \{ 0 \}$, by the continuity of $S$.  This contradicts the injectivity of $S|_N$.  
        \end{case}   
        \begin{case}[$ \| x_n \|$ does not tend to infinity]
            So $(x_n)$ has a bounded subsequence $(x_{n_k})$.  Since $T$ is compact, $(x_{n_k})$ has a subsequence such that $(T x_{n_{k_l}})$ converges, to $z_1$ say.  By replacing $x_n$ by this subsequence we can assume that $Sx_n \rightarrow y$, and that $Tx_n \rightarrow z$.  A before, we can write \begin{align*}
            x_n = S x_n + T x_n &\rightarrow y + z.
            \end{align*}  So $x_n$ converges to $x \in N$.  So $S x_n \rightarrow Sx \in S(N)$ by continuity, but we assume that $S x_n \rightarrow y \in X \backslash S(N)$, which achieves our contradiction.
        \end{case}
    \end{enumerate}  
\end{proof}
% section lecture_23_monday_23_may (end)

\section{Lecture 24 - Wednesday 25 May} % (fold)
\label{sec:lecture_24_wednesday_25_may}
Let $T: \Com^n \rightarrow \Com^n$ be a linear operator.  Then in the simplest case, $T$ has $n$ distinct eigenvalues, and the corresponding eigenvectors are linearly independent, forming a basis for $\Com^n$.  

Hence, $\Com^n = \Com x_1 \oplus \dots \oplus \Com x_n$ and the matrix of $T$ relative to this basis is simply diagonal with $\lambda_1, \dots, \lambda_n$.  

This is not always possible, because there is not always a basis of eigenvectors.  Instead look at the generalised eigenspace, \[
    \{ x \in \Com^n \given \text{$(\lambda I - T)^k x = 0$ for some $k \geq 1$}.  
\] 
But $\{ 0 \} \subseteq \ker(\lambda I - T)^1 \subseteq \ker(\lambda I - T)^2 \subseteq \dots$
 and since $\dim(\Com^n) < \infty$ this must stabilise.  Let $r \geq 1$ be the fist time that $\ker (\lambda I - T)^r = \ker( \lambda I - T)^{r+1}$.  Then the generalised $\lambda$-eigenspace is just $\ker(\lambda I - T)^r$.  There \textbf{is} a basis of $\Com^n$ consisting of generalised eigenvectors, and the matrix of $T$ relative to this basis is in block form.  

\begin{defn}[Complete reduction]
    Let $T: X \rightarrow X$ be linear.  If $X = X_1 \oplus X_2$ be can write \[
        Tx = \begin{pmatrix}
            T_{11} & T_{12} \\
            T_{21} & T_{22}
        \end{pmatrix} \begin{pmatrix}
            x_1 \\
            x_2
        \end{pmatrix}
    \] where we identify $x_1 + x_2 \iff (x_1, x_2)$.  Here, \begin{align*}
        T_{11}: X_1 \rightarrow X_1 \\
        T_{12}: X_2 \rightarrow X_1 \\
        T_{21} : X_2 \rightarrow X_2 \\
        T_{22} : X_2 \rightarrow X_2
    \end{align*} we say that $X = X_1 \oplus X_2$ \textbf{completely reduces} $T$ (well adapted to $T$) if \[
        Tx = \begin{pmatrix}
            T_1 & 0 \\
            0   & T_2 
        \end{pmatrix} \begin{pmatrix}
            x_1 \\
            x_2
        \end{pmatrix}
    \]  We write $T = T_1 \oplus T_2$.
\end{defn}

\begin{exer}
    If $X = X_1 \oplus X_2$ completely reduces $T = T_1 \oplus T_2$, then \begin{enumerate}[(a)]
        \item $\ker T = \ker T_1 \oplus \ker T_2$ 
        \item $\im T = \im T_1 \oplus \im T_2$
        \item $T$ is injective if and only if $T_1, T_2$ are injective
        \item $T$ is surjective if and only if $T_1, T_2$ are surjective
        \item If $T$ is bijective, then $X = X_1 \oplus X_2$ completely reduces $T^{-1} = T_1^{-1} \oplus T^{-1}_2$.
    \end{enumerate}
\end{exer}

\begin{cor}
    Let $X = X_1 \oplus X_2$ be Banach, with $X_1, X_2$ closed subspaces.  If $X = X_1 \oplus X_2$ completely reduces $T = T_1 \oplus T_2 \in \mathcal L(X)$, then \begin{enumerate}[(a)]
        \item $T_1 \in \mathcal L(X_1), T_2 \in \mathcal L(X_2)$
        \item $\sigma(T) = \sigma(T_1) \cup \sigma(T_2)$ 
        \item $\sigma_p(T) = \sigma_p(T_1) \cup \sigma_p(T_2)$
    \end{enumerate}  
\end{cor}

\begin{proof}
    Exercise.
\end{proof}

Consider the following chains \begin{align*}
    \{ 0 \} \subseteq \ker S^1 \subseteq \ker S^2 \subseteq \dots \\
    X \supseteq \im S^1 \supseteq \im S^2 \supseteq \dots
\end{align*} where $X$ is a vector space and $S \in \text{Hom}(X, X)$.  It is easy to see that if $\ker S^r = \ker S^{r+1}$ then $\ker S^r = \ker S^{r+k}$.  Similarly for images (p. 109 in Daners.)

There is no reason that these should stabilise in general.
\begin{thm}
    Let $X$ be Banach, $T \in \mathcal K(X), \lambda \neq 0$.  Then both chains (with $S = \lambda I - T$) stabilise.  
\end{thm}
\begin{proof}
     Without loss of generality, assume $\lambda = 1$, so we can write $S = I - T$.  Suppose that the kernel chain does not stabilise.  Since we assume \[
        \ker S^1 \subsetneq \ker S^2 \subsetneq \ker S^3 \subsetneq
     \]  We know that these are closed (being finite dimensional) subspaces.  So Reisz's Lemma gives $x_n \in \ker S^n$ with $\| x_n \| = 1$, $\|x_n - x \| \geq \frac{1}{2}$ for all $x \in \ker S^{n+1}$. This is a bounded sequence.  We claim that $T x_n$ has no convergent subsequence.  
    
    Let $m > n$.  Then \begin{align*}
        \| Tx_m - Tx_n \|   &= \| ( I - T) x_n - (I-T) x_m + x_m - x_n \| \\
                            &= \| Sx_n - Sx_m - x_m - x_n \|\\
                            &= \| x_m - \underbrace{(S x_m  - S x_n  + x_n)}_\text{in $\ker S^{m-1}$} \| \\
                            &\geq \frac{1}{2}
    \end{align*}  The image argument is similar - using the fact that the images are closed - proved in the previous lecture.
\end{proof}

\begin{thm}
    Let $X$ be a vector space, $S \in \text{Hom}(X, X)$.  Suppose that \begin{align*}
        \alpha(S) &= \inf \{ r \geq 1 \given \ker S^r = \ker S^{r+1} \} \\
        \delta(S) &= \inf \{ r \geq 1 \given \im S^r = \im S^{r+1} \},
    \end{align*} the \textbf{ascent} and \textbf{descent} of $S$ respectively, are both finite.  
    
    Then \begin{enumerate}[(a)]
        \item $\alpha(S) = \delta(S) = r$, say
        \item $X = \ker S^r \oplus \im S^r$
        \item The direct sum in (b) completely reduces $S$. 
    \end{enumerate} 
\end{thm}
\begin{proof}
    Daner's notes, p. 109.
\end{proof}

\begin{cor}
    Let $X$ be Banach, $T \in \mathcal K(X)$, $\lambda \neq 0$.  Let $r = \alpha(\lambda I - T) = \delta(\lambda I - T)$.  Then $X = \ker(\lambda I - T)^r \oplus \im(\lambda I - T)^r$ and this completely reduces $\mu I - T, \mu \in \K$.
\end{cor}

\begin{cor}
    If $X$ is Banach, $T \in \mathcal K(X), \lambda \neq 0$ then $\lambda I - T$ is injective if and only if $\lambda I - T$ is surjective.  
\end{cor}

\begin{proof}
    \begin{align*}
        &\qquad         \text{$\lambda I - T$ injective} \\
        &\Rightarrow 0 \in \ker(\lambda I - T)^1 = \ker(\lambda I - T)^2 \\
        &\Rightarrow \alpha(\lambda I - T) = 1 \\
        &\Rightarrow \delta(\lambda I - T) = 1 \\
        &\Rightarrow X = \underbrace{\ker(\lambda I - T)}_{= \{ 0 \}} \oplus \im(\lambda I - T) \\
        &\Rightarrow X = \im (\lambda I - T) \\
        &\Rightarrow \text{$X$ is surjective}
    \end{align*}  The other direction is similar.
\end{proof}

\begin{cor}
    Let $X$ be Banach, $T \in \mathcal K(X)$.  Thus each $\lambda \in \sigma(T) \backslash \{ 0 \}$ is an eigenvalue.  
\end{cor}
\begin{proof}
    Immediate from the previous corollary.
\end{proof}


% section lecture_24_wednesday_25_may (end)


\section{Lecture 25 - Monday 30 May} % (fold)
\label{sec:lecture_25_monday_30_may}
Recall the following.
\begin{cor}
    Let $X$ be Banach, $T \in \mathcal K(X)$, $\lambda \neq 0$.  Let $r = \alpha(\lambda I - T) = \delta(\lambda I - T)$.  Then $X = \ker(\lambda I - T)^r \oplus \im(\lambda I - T)^r$ and this completely reduces $\mu I - T, \mu \in \K$.
\end{cor}

Also note that $\im \ker(\lambda I - T)^r$ is closed, and $\ker (\lambda I - T)^r$ is finite dimensional.  
\begin{exer}
    Let $\lambda 1, \dots, \lambda_n \in \sigma(T) \backslash \{ 0 \}$.  Let $N_j = \ker(\lambda_j I - T)^r_j$ be the generalised $\lambda_j$-eigenspace.  Show that there exists closed subspaces $M$ with \[
        X = N_1 \oplus N_2 \oplus \cdots \oplus M
    \] with $T = T_1 \oplus T_2 \oplus \cdots \oplus T_M $, and so spectral theory tells us how to \emph{diagonalise} $T$.
\end{exer} 

In Hilbert spaces we can say even more.  Recall that the adjoint of $T \in \mathcal L(\mathcal H)$ is defined by \[
    \iprod{Tx, y} = \iprod{x, T^* y} \quad \forall x, y \in \mathcal H
\]  Then $T^* \in \mathcal L(\mathcal H)$.  
\begin{defn}[Self-adjoint]
$T \in \mathcal L(\mathcal H)$ is \begin{enumerate}[(a)]
    \item \textbf{Hermitian (self-adjoint)} if $T^* = T$.
    \item \textbf{Unitary} if $T^* T = T T^* = I$.  
    \item \textbf{Normal} if $T^* T = T T^*$.  
\end{enumerate}
\end{defn}


\begin{rem}
    For matrices, we have \begin{enumerate}[(a)]
        \item Hermitian if and only if $\overline{A^T} = A$. 
        \item Unitary if and only if the columns of $A$ are orthonormal.
        \item Hermitian and unitary operators are normal.
    \end{enumerate}
\end{rem}

\begin{prop}
    Let $\mathcal H$ be Hilbert over $\Com$.  IF $T \in \mathcal L(\mathcal H)$ is normal, then $r(T) = \| T \|$.  
\end{prop}

\begin{proof}
    For Hermitian operators it is easy.  We have \[
        \| T \|^2 = \| T^* T \| = \| T^2 \|.
    \]  By induction ,we then have $\| T \|^{2^n} = \| T^{2^n} \|$.  So \begin{align*}
        r(T) &= \lim_{n \rightarrow \infty} \| T^n \|^{1/n} \\
            &= \lim_{n \rightarrow \infty} \| T^{2^n} \|^{1/{2^n}} \\
            &= \| T \|.
    \end{align*}  
    
    For normal operators, we have \begin{align*}
        \| T^2 \|^2 &= \| (T^2)^* T^2 \| \\
                    &= \| T^*(T^* T) T \| \\
                    &= \| T^* T T^* T \| \quad \text{normal} \\
                    &= \| (T^* T)^* (T^* T) \|  \\
                    &= \| T^* T \|^2 \\
                    &= \| T^4 \|   
    \end{align*} and then we have $\| T^2 \| = \| T \|^2$ and the proof follows by induction.
\end{proof}

\begin{cor}
    Let $\mathcal H$ be a Hilbert space over $\Com$.  \begin{enumerate}[(a)]
        \item If $T \in \mathcal L(\mathcal H)$ is unitary, then \[
            \sigma(T) \subseteq \mathbb{T} = \{ \lambda \in \Com \given | \lambda | = 1 \}\]
        \item If $T \in \mathcal L(\mathcal H)$ is Hermitian, then \[
            \sigma(T) \subseteq \R.
        \]
    \end{enumerate}
\end{cor}
\begin{proof}{\ }\begin{enumerate}[(a)]
    \item On practice sheet.  Use the fact that $\sigma(T^*) = \overline{\sigma(T)}$.
    \item Let $\lambda = a + ib \in \sigma(T)$.  So $\lambda I - T$ is not invertible.  Hence, $(\lambda + it)I - (T + it I)$ is not invertible for all $t \in \R$. 
  Then \begin{align*}
        \| \lambda + it \|^2    &\leq r(T + itI)^2 \\
                                &\leq \| T + itI \|^2 \\
                                &= \| (T + itI)^* ( T + itI) \| \\
                                &= \| (T - itI)(T + itI) \| \\
                                &= \| T^2 + t^2 I \| \\
                                &\leq \| T^2 + t^2
    \end{align*}  However, the left hand side is equal to \[
        a^2 + b^2 + 2bt + t^2,
    \] and so we obtain \[
        a^2 + b^2 + 2bt \leq \| T \|^2 \quad \forall t \in \R
    \] and so $b = 0$.  
\end{enumerate}
\end{proof}

\begin{lem}
    Let $\mathcal H$ be Hilbert over $\Com$.  Let $T \in \mathcal L(\mathcal H)$, and let \[
        M_\lambda = \{ x \in \mathcal H \given Tx = \lambda x \} = \ker \lambda I - T
    \]  be the $\lambda$-eigenspace of $T$.  Then \begin{enumerate}[(a)]
        \item $M_\lambda \perp M_\mu$ if $\lambda \neq \mu$.  
        \item If $T$ is normal, each $M_\lambda$ is $T$ and $T^*$ invariant.  That is, \[
            T(M_\lambda) \subseteq M_\lambda, \quad T^*(M_\lambda) \subseteq M_\lambda.
        \]
    \end{enumerate}
\end{lem}

\begin{proof}{\ }
    \begin{enumerate}[(a)]
        \item Let $u \in M_\lambda, v \in M_\mu$.  Then \begin{align*}
            (\lambda - \mu) \iprod{u, v} &= \iprod{\lambda u, v} - \iprod{u, \overline \mu v} \\
            &= \iprod{Tu, v} - \iprod{u, T^* v} \\
            &= \iprod{Tu, v} - \iprod{Tu, v} \\
            &= 0
        \end{align*} and so $\iprod{u, v} = 0$.  
        \item If $T$ is normal, then $\ker T = \ker T^*$ as \begin{align*}
            \| Tx \|^2 &= \iprod{Tx, Tx} = \iprod{x, T^* T x} \\
                    &= \iprod{x, T T^* x} = \iprod{T*x, T^* x} \\
                    &= \| T^* x \|^2.
        \end{align*}  Similarly, if $T$ is normal then $\lambda I - T$ is normal.  Then \begin{align*}
            M_\lambda   &= \ker \lambda I  - T \quad \text{($T$ invariant)} \\
                        &= \ker \overline \lambda I  - T^* \quad \text{($T^*$ invariant)}.
        \end{align*}
    \end{enumerate}
\end{proof}

The spectral theory for compact normal operators in a Hilbert space is particularly nice, as the following theorem demonstrates.
\begin{thm}
    Let $T \in \mathcal L(\mathcal H)$ be compact and normal.  Then \[
        \mathcal H = \overline{\bigoplus_{\lambda \in \sigma(T)} M_\lambda},
    \] the closure of the span of the eigenspaces, and $\mathcal H$ has an orthonormal basis consisting of eigenvectors.  Moreover, $T$ acts diagonally with respect to this basis.   
\end{thm}
\begin{proof}
    Let \[
        M = \overline{\bigoplus_{\lambda \in \sigma(T)} M_\lambda},
    \] a closed subspace.  Hence $H = M \oplus M^\perp$, where \[
    M^\perp = \{ x \in \mathcal H \given \iprod{x, m} = 0 \, \forall m \in M \}.
    \]   We must show that $M^\perp = \{ 0 \}$.  Assume the contrary.  Then consider $\tilde T = M^\perp \rightarrow \mathcal H$ be the restriction of $T$ to $M^\perp$.  Then we have \[
        \tilde T: M^\perp \rightarrow M^\perp
    \] is compact and normal (Exercise). Then  \begin{enumerate}[(a)]
        \item $\sigma(\tilde T) = \{ 0 \}$.  Then $r(\tilde T) = 0$, and so $\| \tilde T \| = 0$, and so $\tilde T = 0$.  Then each $x \in M^\perp \backslash \{ 0 \}$ satisfies $\tilde T x = 0 = 0x$, and so $x \in M_0$ with $M^\perp \subseteq M_0 \subseteq M$, a contradiction (from direct sum decomposition).  Hence $M = \{ 0 \}$.  
        \item $\sigma(\tilde T) \neq \{ 0 \}$.  So there is an eigenvalue $\lambda \in \sigma(T) \backslash \{ 0 \}$.  So there is $x \in M^\perp \backslash \{ 0 \}$ with $\tilde T x = \lambda x$.  o $Tx = \lambda x$, and so $x \in (M_\lambda \cap M^\perp) \backslash \{ 0 \}$, a contradiction.  Hence $M^\perp = \{ 0 \}$.    
    \end{enumerate}
    
    Choose an orthonormal basis for each $M_\lambda$, and combine to get an orthonormal basis of $\mathcal H$, using $M_\lambda \perp M_\mu$.  
\end{proof}  


% section lecture_25_monday_30_may (end)


\section{Lecture 26 - Wednesday 1 June} % (fold)
\label{sec:lecture_26_wednesday_1_june}
\subsection{Fredholm alternative for compact operators on a Hilbert space} % (fold)
\label{sub:fredholm_alternative_for_compact_operators_on_hilbert_space}

% subsection fredholm_alternative_for_compact_operators_on_hilbert_space (end)
Recall that for matrices, we have the following result, known as the Fredholm alternative.    

\begin{thm}[Fredhold alternative (Finite dimensional spaces)]
    Let $A: \Com^n \rightarrow \Com^n$ be linear.  Then exactly one of the following two things occur:
    \begin{enumerate}[(1)]
        \item $Ax = 0$ has only the trivial solution $x = 0$, in which case $Ax = b$ has a unique solution for each $b \in \Com^n$.  
        \item $Ax = 0$ has a non-trivial solution, in which case $Ax = b$ has either no solutions, or infinitely many solutions.
    \end{enumerate}
\end{thm}

\begin{defn}[Hilbert-Schmidt integral operators]
    \mapping{T}{L^2([a,b])}{L^2([a,b])}{(Tf)(x)}{\int_a^bK(x, y) f(y) \, dy} where $\| K \|_2$ is finite.  These are compact operators.    
\end{defn}

Consider equations of the following form\[
    \lambda f(x) - \int_a^b K(x, y) f(y) \, dy = g(x),
\] where $\lambda \neq 0$ and $g \in L^2$ are given. This can be rewritten in the form \[
    (\lambda I - T) f = g.
\]  Then we have the following theorem, due to Fredholm. 

\begin{thm}[Fredholm alternative (Hilbert spaces)]
    Let $\mathcal H$ be Hilbert over $\Com$, and let $T \in \mathcal K(\mathcal H)$.  Then exactly one of the following occurs.
    \begin{enumerate}[(a)]
        \item $(\lambda I - T) = 0$ has only the trivial solution, in which case $(\lambda I - T)x = b$ has a unique solution for each $b \in \mathcal H$.  
        \item $(\lambda I - T) x = 0$ has a non trivial solution, in which case $(\lambda I - T) x = b$ has a solution if and only if $b \perp y$ for every solution $y$ of the equation \[
            (\overline \lambda I - T^*) y = 0
        \]  This is finite dimensional, as it is the kernel of $(\lambda I - T)^*$.   
    \end{enumerate}
\end{thm}
    
\begin{proof}
    {\ } \begin{enumerate}[(a)]
        \item If $(\lambda I - T) x = 0$ has only the trivial solution, then $\ker \lambda I - T = \{ 0 \}$ and so it is injective.  Hence $\lambda$ is not an eigenvalue, and so $\lambda$ is not a spectral value.  So $\lambda I - T$ is invertible, and so $(\lambda I - T) x = b$ has a unique solution $x = (\lambda I - T)^{-1} b$, which can be expanded into a series expression if $|\lambda| > r(T)$.  
        \item Suppose $(\lambda I - T) x = 0$ has a non-trivial solution.  Then
        \begin{align*}
            &\qquad\text{$(\lambda I - T) x = b$ has a solution} \\
            &\iff b \in \im \lambda I - T \quad \text{which is closed} \\
            &\iff b \in ((\im \lambda I - T)^\perp)^\perp \\
            &\iff b \in (\ker \overline \lambda - T^*)^\perp \\
            &\iff b \perp y \quad \forall y \in \ker \overline \lambda I - T^*.\qedhere
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{prop}[Miscelaneous]{\ }\begin{enumerate}[(a)]
    \item If $M$ is a closed subspace of $\mathcal H$, then $M = M^{\perp \perp}$. 
    \item IF $S: \mathcal H \rightarrow \mathcal H$ and $S \in \mathcal L(\mathcal H)$, then $(\im S)^\perp = \ker S^*$.  
\end{enumerate}
\end{prop}

\begin{proof}{\ }
    \begin{enumerate}[(a)]
        \item Let $m \in M$, then $\iprod{m, x} = 0$ for all $x \in M^\perp$, and so $m \in (M^\perp)^\perp = M^{\perp \perp}$, and so $M \subseteq M^{\perp \perp}$.  
        
        Let $x \in M^{\perp \perp}$.  Since $M$ is closed, $\mathcal H = M \oplus M^{\perp}$, and so $x = m + m^\perp$.  So $x - m \in M^{\perp \perp} + M \subseteq M^{\perp \perp}$, and so $x - m = m^\perp \in M^{\perp \perp}$.  But $M^\perp$ is closed, and so $\mathcal H = M^\perp \oplus M^{\perp \perp}$.  So $x - m - 0$, and $x = m \in M$.  
        \item \begin{align*}
            (\im S)^\perp &= \{ x \in \mathcal H \given \iprod{x, sy} = 0 \quad \forall y \in \mathcal H \} \\
                            &= \{ x \in \mathcal H \given \iprod{S^* x, y} = 0 \quad \forall y \in \mathcal H \} \\
                            &= \{ x \in H \given S^* x = 0 \} \\
                            &= \ker S^*
        \end{align*} 
    \end{enumerate}
\end{proof}
% section lecture_26_wednesday_1_june (end)










\end{document}
